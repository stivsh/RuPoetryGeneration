{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from clear_texts import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def loggin(log_str):\n",
    "    print(log_str)\n",
    "    \n",
    "print(tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for generating traning sequenses, decodinn, encoding, text generation\n",
    "text = ''.join(get_textes())\n",
    "\n",
    "def get_encode_and_decode_dicts(text):\n",
    "    later_counter = Counter()\n",
    "    later_counter.update(text)\n",
    "    alphabit = set(later_counter.keys())\n",
    "\n",
    "    charter_to_inx = { ch:inx for inx,ch in enumerate(alphabit)}\n",
    "    inx_to_charter = { inx:ch for ch,inx in charter_to_inx.items()}\n",
    "    return charter_to_inx, inx_to_charter, alphabit\n",
    "\n",
    "\n",
    "charter_to_inx, inx_to_charter, alphabit = get_encode_and_decode_dicts(text)\n",
    "alphabit_size = len(alphabit)\n",
    "\n",
    "def encode_seq(seq):\n",
    "    return  np.array([ charter_to_inx[ch] for ch in seq ])\n",
    "\n",
    "def decode_seq(seq):\n",
    "    return \"\".join([ inx_to_charter[inx] for inx in seq ])\n",
    "\n",
    "\n",
    "def sequenses_generator(text, batch_len, seq_length):\n",
    "    while True:\n",
    "        X = []\n",
    "        while len(X) < batch_len:\n",
    "            shift = np.random.randint(len(text)-seq_length)\n",
    "            seq_in = text[shift:seq_length+shift]\n",
    "            X.append(encode_seq(seq_in))\n",
    "        yield np.array(X)\n",
    "\n",
    "        \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def rnn_placeholders(state):\n",
    "    \"\"\"Convert RNN state tensors to placeholders with the zero state as default.\"\"\"\n",
    "    if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\n",
    "        c, h = state\n",
    "        c = tf.placeholder_with_default(c, c.shape, c.op.name)\n",
    "        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n",
    "        return tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "    elif isinstance(state, tf.Tensor):\n",
    "        h = state\n",
    "        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n",
    "        return h\n",
    "    else:\n",
    "        structure = [rnn_placeholders(x) for x in state]\n",
    "        return tuple(structure)\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, sess, seq_length, alphabit_size, verbas = True,  state_sizes=[128,128]):\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        self.state_sizes = state_sizes\n",
    "        \n",
    "        if verbas: loggin('Create NN')\n",
    "        \n",
    "        #data paceholder\n",
    "        self.train_input = tf.placeholder(tf.int32, [None, seq_length])\n",
    "        one_hot_input = tf.one_hot(self.train_input, alphabit_size)\n",
    "        if verbas: loggin('rnn_cell input shape %s' % str(one_hot_input.get_shape()))\n",
    "        \n",
    "        #define weights and rnn cells\n",
    "        #add LSTM cells\n",
    "        def lstm_cell(state_size):\n",
    "            return tf.contrib.rnn.BasicLSTMCell(state_size)\n",
    "        \n",
    "        cells = [lstm_cell(_) for _ in state_sizes ]\n",
    "        self.rnn_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "                \n",
    "        #add output layer waights\n",
    "        if verbas: loggin('rnn_cell output shape %s' % str(state_sizes[-1]))\n",
    "                \n",
    "        self.output_w = tf.get_variable(shape=(state_sizes[-1], alphabit_size),\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(), name = \"out_w\")\n",
    "        \n",
    "        self.output_b = tf.get_variable(shape=(alphabit_size),initializer=tf.constant_initializer(0.0), name = \"out_b\")\n",
    "\n",
    "        if verbas: loggin('w shape %s, b shape %s' % (str(self.output_w.shape), str(self.output_b.shape)) ) \n",
    "            \n",
    "        #1)deffine learning graph\n",
    "        #forwarg pass\n",
    "        with tf.variable_scope(\"rnn_layer\"):\n",
    "            lstm_output, lstm_states = tf.nn.dynamic_rnn(self.rnn_cell, one_hot_input, dtype = tf.float32)\n",
    "        \n",
    "        #we need only last 1/4\n",
    "        start_position = seq_length//4\n",
    "        count = seq_length-start_position-1\n",
    "        \n",
    "        trancated_lstm_output = tf.slice(lstm_output, begin = [0,start_position,0], size = [-1,count,-1])\n",
    "        if verbas: loggin('trancated_lstm_output shape %s'% str( trancated_lstm_output.get_shape() ) )\n",
    "        \n",
    "        rnn_output = tf.reshape(trancated_lstm_output, [-1,state_sizes[-1]])\n",
    "        if verbas: loggin('rnn_output shape %s'% str( rnn_output.get_shape() ) )\n",
    "        \n",
    "        output_layer = tf.nn.xw_plus_b(rnn_output,self.output_w,self.output_b)\n",
    "        if verbas: loggin('output_layer shape %s'% str( output_layer.get_shape() ) )\n",
    "        \n",
    "        target = tf.reshape(tf.slice(one_hot_input, begin = [0,start_position+1,0], size = [-1,count,-1]),[-1,alphabit_size])\n",
    "        if verbas: loggin('target shape %s'% str( target.get_shape() ) )\n",
    "        \n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output_layer))\n",
    "        if verbas: loggin('self.loss shape %s'% str( self.loss.get_shape() ) )\n",
    "        \n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learning_rate).minimize(self.loss)   \n",
    "            \n",
    "        #2)deffine acc func\n",
    "        pred_classes = tf.argmax(output_layer, axis=1)\n",
    "        y_classes = tf.argmax(target ,axis = 1)\n",
    "            \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(pred_classes, y_classes), tf.float32))\n",
    "        \n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('accuracy', self.accuracy)\n",
    "        self.merged_summary = tf.summary.merge_all()\n",
    "        \n",
    "        #3)predict next charter graph\n",
    "        \n",
    "        \n",
    "        self.input = tf.placeholder(tf.int32)\n",
    "        self.input_state = rnn_placeholders(self.rnn_cell.zero_state(1,tf.float32))\n",
    "        \n",
    "        rnn_input = tf.reshape(tf.one_hot(self.input, alphabit_size), [1,1,alphabit_size])\n",
    "        with tf.variable_scope(\"rnn_layer\"):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            predict_rnn_output, self.output_state = tf.nn.dynamic_rnn(self.rnn_cell,\n",
    "                                                                rnn_input, dtype = tf.float32,\n",
    "                                                                initial_state = self.input_state )\n",
    "        \n",
    "        predict_rnn_output = tf.reshape(predict_rnn_output, [-1,state_sizes[-1]])\n",
    "        \n",
    "        predict_output_layer = tf.nn.xw_plus_b(predict_rnn_output,self.output_w,self.output_b) \n",
    "        \n",
    "        self.predict_output = tf.nn.softmax(predict_output_layer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def train_on_batch(self, batch, learning_rate = 1e-3):\n",
    "        feed = {self.train_input: batch,self.learning_rate:learning_rate}\n",
    "        return self.sess.run([ self.loss, self.optimizer ], feed)[0]\n",
    "    \n",
    "    def get_loss(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.loss, feed)\n",
    "    \n",
    "    def get_accuracy(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.accuracy, feed)\n",
    "    \n",
    "    def get_summary(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.merged_summary, feed)\n",
    "    \n",
    "    def get_accuracy_for_seq(self,seq):\n",
    "        encoded = encode_seq(seq)\n",
    "        predicted = []\n",
    "        self.reset_state()\n",
    "        for _ in encoded:\n",
    "            predicted.append( self.step(_) )\n",
    "        eq_count = sum( [ int(_[1] == _[0].argmax()) for _ in zip(predicted[:-1], list(encoded)[1:]) ] )\n",
    "        return eq_count/len(predicted)\n",
    "    \n",
    "    def step(self ,ch_inx):\n",
    "        feed = {self.input: ch_inx, self.input_state: self.curent_state}\n",
    "        out, self.curent_state = self.sess.run([self.predict_output, self.output_state], feed)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.curent_state = self.sess.run(self.rnn_cell.zero_state(1,tf.float32))\n",
    "      \n",
    "    def __deffault_fname__(self):\n",
    "        fname = \"statesize-%s-cellcount-%s-.ckpt\" % (\n",
    "            str(self.state_sizes[-1]),str(len(self.state_sizes)) )\n",
    "        return fname\n",
    "        \n",
    "    def save(self, fname = None, loss = None):\n",
    "        savepath = \"model_waights\"\n",
    "        \n",
    "        if not fname: fname = self.__deffault_fname__()\n",
    "        if loss: fname = \"loss-%s-\"%(str(loss))+fname\n",
    "        fname = join(savepath, fname)\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, fname)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "    def load(self, fname = None):\n",
    "        savepath = \"model_waights\"\n",
    "        \n",
    "        if not fname: fname = self.__deffault_fname__()\n",
    "        fname = join(savepath, fname)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, fname)\n",
    "\n",
    "    def load_best(self):\n",
    "        savepath = \"model_waights\"\n",
    "        files = [f for f in listdir(savepath) if isfile(join(savepath, f))]\n",
    "        \n",
    "        all_checkpoint_parameters = []\n",
    "        for fname in files:\n",
    "            checkpoint_parameters = {\"fname\":fname}\n",
    "            parts_of_name = fname.split('-')\n",
    "            while len(parts_of_name)>1:\n",
    "                key = parts_of_name[0]\n",
    "                value = parts_of_name[1]\n",
    "                checkpoint_parameters[key] = value\n",
    "                parts_of_name = parts_of_name[2:]\n",
    "                all_checkpoint_parameters.append(checkpoint_parameters)\n",
    "                \n",
    "        all_checkpoint_parameters = [par for par in all_checkpoint_parameters\n",
    "                                     if \"statesize\" in par and \"cellcount\" in par and \"loss\" in par  ]\n",
    "        \n",
    "        all_checkpoint_parameters = [par for par in all_checkpoint_parameters\n",
    "                                     if int(par[\"statesize\"])==self.state_sizes[-1] and int(par[\"cellcount\"])==len(self.state_sizes) ]       \n",
    "         \n",
    "        if not len(all_checkpoint_parameters):\n",
    "            loggin('No checkpoints for this model')\n",
    "            return\n",
    "        \n",
    "        all_checkpoint_parameters = sorted(all_checkpoint_parameters, key=lambda x: float(x['loss']))  \n",
    "        fname = all_checkpoint_parameters[0]['fname'].split('.ckpt')[0]+'.ckpt'\n",
    "        loggin('loaded from %s' % fname)\n",
    "        self.load(fname)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, eps_count = 10, batch_len = 256, batchs_in_ep = 256, learning_rate = 1e-3):\n",
    "    \n",
    "    print('gen:+',decode_seq(generate(model, 100)),'+')\n",
    "    \n",
    "    texts = get_textes()\n",
    "    random.shuffle(texts)\n",
    "    train_text = ''.join(texts[50:])\n",
    "    test_text = ''.join(texts[:50])\n",
    "    seed = np.random.randint(100000)\n",
    "    np.random.seed(123)\n",
    "    x_for_loss_check = sequenses_generator(test_text, 512, seq_length).__next__()\n",
    "    np.random.seed(seed)\n",
    "   \n",
    "    data_gen = sequenses_generator(train_text, batch_len, seq_length)\n",
    "    \n",
    "    min_loss = model.get_loss(x_for_loss_check)\n",
    "    \n",
    "    for ep in range(eps_count):\n",
    "        for batches_processed in tqdm(range(batchs_in_ep)):\n",
    "            train_x = data_gen.__next__()\n",
    "            train_loss = model.train_on_batch(train_x, learning_rate = learning_rate)\n",
    "        \n",
    "        loss = model.get_loss(x_for_loss_check)\n",
    "        acc = model.get_accuracy_for_seq(test_text)\n",
    "        \n",
    "        if min_loss > loss:\n",
    "            min_loss = loss\n",
    "            model.save(loss = loss)\n",
    "            \n",
    "        print('ep %s acc %s, last loss %s, train_loss: %s' % ( ep,str(acc), str(loss), str(train_loss) ) )\n",
    "        print('gen:+',decode_seq(generate(model, 100)),'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create NN\n",
      "rnn_cell input shape (?, 200, 41)\n",
      "rnn_cell output shape 512\n",
      "w shape (512, 41), b shape (41,)\n",
      "trancated_lstm_output shape (?, 49, 512)\n",
      "rnn_output shape (?, 512)\n",
      "output_layer shape (?, 41)\n",
      "target shape (?, 41)\n",
      "self.loss shape ()\n",
      "gen:+ !!!! +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-3.1711-statesize-512-cellcount-3-.ckpt\n",
      "ep 0 acc 0.16497626000312074, last loss 3.1711, train_loss: 3.17264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+  оо                                                                                                  +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-3.14989-statesize-512-cellcount-3-.ckpt\n",
      "ep 1 acc 0.16589019415527964, last loss 3.14989, train_loss: 3.13962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+  ее                                                                                                  +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.95717-statesize-512-cellcount-3-.ckpt\n",
      "ep 2 acc 0.1973874857894385, last loss 2.95717, train_loss: 2.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ о оое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое ое о +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.7486-statesize-512-cellcount-3-.ckpt\n",
      "ep 3 acc 0.22052562359287578, last loss 2.7486, train_loss: 2.75367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ поее ие ие ое ое ое ое ое о ое ое о ое ое о ое ое о ое ое о ое ое о ое ое о ое ое о ое ое о ое ое о  +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.56147-statesize-512-cellcount-3-.ckpt\n",
      "ep 4 acc 0.24593745123826932, last loss 2.56147, train_loss: 2.56379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ проос сорет серовной с серот с серова с серова с серова с серова с серова с серова с серова с серова +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.48602-statesize-512-cellcount-3-.ckpt\n",
      "ep 5 acc 0.262499721361539, last loss 2.48602, train_loss: 2.48435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ рроорет серотной с серотной с серотной с серотной с серотной с серотной с серотной с серотной с серо +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.42744-statesize-512-cellcount-3-.ckpt\n",
      "ep 6 acc 0.2846793428590535, last loss 2.42744, train_loss: 2.37958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ роортем сорет с серовной стероть с стем с стем с стем с стем с стем с стем с стем с стем с стем с ст +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-2.33489-statesize-512-cellcount-3-.ckpt\n",
      "ep 7 acc 0.30170972559684356, last loss 2.33489, train_loss: 2.32403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen:+ роедт салной поледа не стороть и полет не стореть и полет не стореть и полет не стореть и полет не с +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/64 [00:04<01:32,  1.51s/it]"
     ]
    }
   ],
   "source": [
    "seq_length = 200\n",
    "\n",
    "eps_count = 20\n",
    "batch_len = 256\n",
    "batchs_in_ep = 64\n",
    "\n",
    "state_sizes = [512,512,512]\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "new_model = True\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        model = Model(sess, seq_length = seq_length, verbas = True,\n",
    "                      alphabit_size = alphabit_size, state_sizes = state_sizes)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if not new_model: model.load_best()\n",
    "        \n",
    "        train(model, eps_count = eps_count, batch_len = batch_len, batchs_in_ep = batchs_in_ep, learning_rate = learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "state_sizes = [512,512,512]\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        model = Model(sess, seq_length = seq_length, verbas = True,\n",
    "                      alphabit_size = alphabit_size, state_sizes = state_sizes)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        model.load_best()\n",
    "        \n",
    "        print('generate random poetry:')\n",
    "        print('gen:+',decode_seq(generate(model, 10000, sampling = False, pattern = \"о любви.\")),'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
