{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stiv/Projects/DataScience/RuPoetry/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and prepare textes    \n",
    "\n",
    "def prepare_texts(textes):\n",
    "    \n",
    "    #remove some laters\n",
    "    replasements = [('\\t',''),\n",
    "                   ('»','\"'),\n",
    "                   ('«','\"'),\n",
    "                   ('—','-'),\n",
    "                   (';',','),\n",
    "                   (':',','),\n",
    "                   ('\\n',' '),\n",
    "                   ('#',' ')]\n",
    "    \n",
    "    def perform_repls(text):\n",
    "        for r in replasements:\n",
    "            text = text.replace(r[0],r[1])\n",
    "        return text\n",
    "        \n",
    "    textes = [ perform_repls(t) for t in textes ]\n",
    "    \n",
    "    #remove reare laters\n",
    "    later_counter = Counter()\n",
    "    for t in textes:\n",
    "        later_counter.update(t)\n",
    "    total_count = sum(later_counter.values())\n",
    "    later_prob = { later:count/total_count for later,count in later_counter.most_common() }\n",
    "    z_prob = later_prob['ё']\n",
    "    alphabit = set([ l for l,prob in later_prob.items() if prob >= z_prob ])\n",
    "    \n",
    "    def remove_reare(text):\n",
    "        return ''.join([ l if l in alphabit else ' ' for l in text  ])\n",
    "    \n",
    "    textes = [ remove_reare(t) for t in textes ]\n",
    "    \n",
    "    #remove multiple spaces\n",
    "    textes = [ \" \".join(t.split()) for t in textes ]\n",
    "    \n",
    "    #remove too short and long\n",
    "    textes = [ t for t in textes if len(t) > 400 and len(t) < 2000 ]\n",
    "    \n",
    "    #add end of poem symbol\n",
    "    textes = [ t+'#' for t in textes if len(t) > 400 and len(t) < 2000 ]\n",
    "    \n",
    "    return textes\n",
    "\n",
    "def load_textes():\n",
    "    textes = None\n",
    "    if not os.path.isfile('data/textes.pkl'):\n",
    "        print('prepare textes')\n",
    "        with open('data/poems.pkl','rb') as f:\n",
    "            poems = pickle.load(f)\n",
    "        textes = [ poem['text'].lower() for poem in poems ]\n",
    "        textes = prepare_texts(textes)\n",
    "        with open('data/textes.pkl', 'wb') as f:\n",
    "            pickle.dump(textes, f)\n",
    "    else:\n",
    "        with open('data/textes.pkl','rb') as f:\n",
    "            textes = pickle.load(f)\n",
    "    return textes\n",
    "\n",
    "def get_encode_and_decode_dicts(textes):\n",
    "    alphabit = None\n",
    "    charter_to_inx = None\n",
    "    inx_to_charter = None\n",
    "    if not os.path.isfile('data/enc_dec_dicts.pkl'):\n",
    "        print('create enc/dec dictionaries')\n",
    "        later_counter = Counter()\n",
    "        for t in textes:\n",
    "            later_counter.update(t)\n",
    "        alphabit = set(later_counter.keys())\n",
    "    \n",
    "        charter_to_inx = { ch:inx for inx,ch in enumerate(alphabit)}\n",
    "        inx_to_charter = { inx:ch for ch,inx in charter_to_inx.items()}\n",
    "        with open('data/enc_dec_dicts.pkl', 'wb') as f:\n",
    "            pickle.dump({\n",
    "               'alphabit':alphabit,\n",
    "                'charter_to_inx':charter_to_inx,\n",
    "                'inx_to_charter':inx_to_charter\n",
    "                }, f)\n",
    "    else:\n",
    "        with open('data/enc_dec_dicts.pkl','rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            alphabit = data['alphabit']\n",
    "            charter_to_inx = data['charter_to_inx']\n",
    "            inx_to_charter = data['inx_to_charter']\n",
    "        \n",
    "    return charter_to_inx, inx_to_charter, alphabit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textes = load_textes()\n",
    "charter_to_inx, inx_to_charter, alphabit = get_encode_and_decode_dicts(textes)\n",
    "\n",
    "#constants for generating learning sequenses\n",
    "alphabit_size = len(alphabit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_charter(ch):\n",
    "    encoded_charter = np.zeros((alphabit_size))\n",
    "    encoded_charter[charter_to_inx[ch]] = 1\n",
    "    return encoded_charter\n",
    "    \n",
    "\n",
    "def encode_seq(seq):\n",
    "    encoded = np.zeros((len(seq),alphabit_size))\n",
    "    for inx,ch in enumerate(seq):\n",
    "        encoded[inx][charter_to_inx[ch]] = 1\n",
    "    return encoded\n",
    "\n",
    "def decode_seq(seq):\n",
    "    return \"\".join([ inx_to_charter[vec.argmax()] for vec in seq ])\n",
    "\n",
    "def sequenses_generator(batch_len = 1024,seq_length = 64):\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        while len(X) < batch_len:\n",
    "            poem_inx = random.randint(0,seq_length-1)\n",
    "            poem = textes[poem_inx]\n",
    "            \n",
    "            if len(poem)+1 < seq_length:\n",
    "                continue\n",
    "            \n",
    "            start_index = random.randint(0,len(poem)-seq_length-1)\n",
    "            sequence = poem[start_index:start_index+seq_length]\n",
    "            next_char = poem[start_index+seq_length]\n",
    "            X.append(encode_seq(sequence))\n",
    "            Y.append(encode_charter(next_char))\n",
    "            \n",
    "        yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024*10\n",
    "seq_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers \n",
    "lstm_layer = layers.LSTM(128, input_shape=(seq_size, len(alphabit)), return_sequences=True)\n",
    "lstm_layer2 = layers.LSTM(128)\n",
    "dense_layer = layers.Dense(len(alphabit), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model for learning\n",
    "model = keras.models.Sequential()\n",
    "model.add(lstm_layer)\n",
    "model.add(lstm_layer2)\n",
    "model.add(dense_layer)\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for generation\n",
    "\n",
    "r_lstm_layer = layers.LSTM(128, input_shape=(seq_size, len(alphabit)), return_state = True)\n",
    "reshapor = layers.Reshape((1, 128))\n",
    "r_lstm_layer2 = layers.LSTM(128, input_shape=(seq_size, 128), return_state = True)\n",
    "r_dense_layer = layers.Dense(len(alphabit), activation='softmax')\n",
    "# Define the input of your model with a shape \n",
    "inp_x = keras.layers.Input(shape=(1,len(alphabit)))\n",
    "# Define s0, initial hidden state for the decoder LSTM\n",
    "ai0 = keras.layers.Input(shape=(128,), name='a0')\n",
    "ci0 = keras.layers.Input(shape=(128,), name='c0')\n",
    "ai1 = keras.layers.Input(shape=(128,), name='a1')\n",
    "ci1 = keras.layers.Input(shape=(128,), name='c1')\n",
    "\n",
    "ao0, _, co0 = r_lstm_layer(inp_x, initial_state=[ai0, ci0])\n",
    "ao1, _, co1 = r_lstm_layer2(reshapor(ao0), initial_state=[ai1, ci1])\n",
    "\n",
    "out = r_dense_layer(ao1)   \n",
    "gen_model = keras.models.Model(inputs=[inp_x, ai0, ci0, ai1, ci1], outputs=[out,ao0,co0, ao1, co1])\n",
    "\n",
    "def load_weights():\n",
    "    r_lstm_layer.set_weights(lstm_layer.get_weights())\n",
    "    r_lstm_layer2.set_weights(lstm_layer2.get_weights())\n",
    "    r_dense_layer.set_weights(dense_layer.get_weights())\n",
    "    \n",
    "def get_initial_state():\n",
    "    a0_initializer = np.zeros((1, 128))\n",
    "    c0_initializer = np.zeros((1, 128))\n",
    "    a1_nitializer = np.zeros((1, 128))\n",
    "    c1_nitializer = np.zeros((1, 128))\n",
    "    return [a0_initializer, c0_initializer, a1_nitializer, c1_nitializer]\n",
    "\n",
    "def propagate(priv_char, state):\n",
    "    probs,next_a0, next_c0,next_a1, next_c1 = \\\n",
    "        gen_model.predict([priv_char.reshape((1, 1, len(alphabit))),*state])\n",
    "    return probs, [next_a0, next_c0,next_a1, next_c1]\n",
    "\n",
    "def gen_string(strlen, randomize = True, randomize_words_begins = True):\n",
    "    load_weights()\n",
    "\n",
    "    \n",
    "    gend_simbols = []\n",
    "    \n",
    "    state = get_initial_state()\n",
    "\n",
    "    priv_char = np.zeros((len(alphabit),))\n",
    "    \n",
    "    for i in range(strlen):\n",
    "        probs,state = propagate(priv_char, state)\n",
    "        if randomize or (randomize_words_begins and (not len(gend_simbols) or gend_simbols[-1]==' ')):\n",
    "            new_char_inx = np.random.choice(probs.size, p=probs[0])\n",
    "        else:\n",
    "            new_char_inx = probs.argmax()\n",
    "            \n",
    "        priv_char = np.zeros((len(alphabit),))\n",
    "        priv_char[new_char_inx]=1\n",
    "        gend_simbols.append(inx_to_charter[new_char_inx])\n",
    "    \n",
    "    return \"\".join(gend_simbols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "argmax: без нем сверкая трепетной позвозна, воспьяцая любовь, и сили в после онятся в мукан прострака. как б\n",
      "words_: перед или светет воденженьяй волне у не так и покой! оскаки огнав была ученьи, это любовью вечной га\n",
      "probs_: лййййй. ужней, # ожно жам с тержене люблююэмие елонул, устропинил, овяже! нахоматна, но уцны лияа, м\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 90s 9ms/step - loss: 1.3800\n",
      "epoch 2\n",
      "argmax: бего, чертополо не смелей, как волна мне страшно наша пригужал ирожный и поморны. но от нарадах рази\n",
      "words_: , и былого цветом оида. что - цветы мечта не трав, над оберной бесные блеснет, полоснувшее давно, ид\n",
      "probs_: что скердепленья, - мне прешит. онта колышкой смолкая траве поснут, другу на нашиши вечаеверный ирик\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 92s 9ms/step - loss: 1.3184\n",
      "epoch 3\n",
      "argmax: бй, что не спастиные с морящи последний мне не смотрить я снилась стары - на миг ты собою, не смолка\n",
      "words_: го, жесточной грусть! # накак все не утрата колед, но мольных ти, приженых слово! ты стал. как бы та\n",
      "probs_: что не горог и не смотрикать готовы. но лишь только наше кровью, и суни пуштая - тои, как вочаственн\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 98s 10ms/step - loss: 1.3482\n",
      "epoch 4\n",
      "argmax: лй-йб# нна с ракой сирию и грудь, и горит - гроский на сирегрий и грудь, и горде - на сираи и грудь,\n",
      "words_: мйного  жувати и кормали она моя ты жажде друг! молча развечь молчится матера в заметива лишь холос \n",
      "probs_: й, чертой дохнут лудь образиль тоб услава замет, мы поволны. да врысть! и, скажи, поеди саль и подае\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 102s 10ms/step - loss: 1.3315\n",
      "epoch 5\n",
      "argmax: лй-йб# нербдель у не ны тверный наситветь и скромний на нем не труне! не страсненья труг когде немне\n",
      "words_: й, что уж ясли ушарая, над облюбенных морокной просезну в руку под мертветном дальке море ямы крапив\n",
      "probs_: й, кто волну отруднет в черь и я поноча я слишный тобою ожатл я не там жилы взораски, ененой великай\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 104s 10ms/step - loss: 1.2871\n",
      "epoch 6\n",
      "argmax: бего, чтобы сердце не спою, налабоматся, над волны. но я люблю только полет, не смела, под корос я з\n",
      "words_: жблёйм й тайдерь мои скаждрая скаждрый соровим созчаом задемнисный слазка дный сожданья скаждря. я р\n",
      "probs_: й, как легкой жизни? вмоден бедужты, в темно святи кустил, едох, смотками на чишен, как волю да же з\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 117s 11ms/step - loss: 1.3087\n",
      "epoch 7\n",
      "argmax: бего, что крова нали словом, что цедом трудь на миг под нем счастье направил мне не головкой походищ\n",
      "words_: лй-йх#еесли сила! е, что тело, что тело, не сестел, е странеш, от меном голомных, о весны, е, те стр\n",
      "probs_: талкно верт в\" - погидить их, как дважно, страшно. у счастье не спытая рукам. и звезды, ничто нашах \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 116s 11ms/step - loss: 1.4069\n",
      "epoch 8\n",
      "argmax: бй переду - я скажи мне. кто я не сумем весно сини выдум. любовь, и сильных сердце сомной, жгучье кр\n",
      "words_: бй переду их и звезды их тебе я кормались среди ль своей! послена. созвучья плет. хотя люблю ее улиб\n",
      "probs_: жбли ое в дах додкам робса. #  поверы смелых чашй скромеждо подмоспыт веноверовё поднад поверв вина.\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 122s 12ms/step - loss: 1.3414\n",
      "epoch 9\n",
      "argmax: безумный страданный тебя леруть, и сильнее под нем сперами и корман пошенный. молчины. напев перель \n",
      "words_: хну и смеет, как и сталый над водовной напрани много не умершенья не похожа. и встала бесстрастной м\n",
      "probs_: лй-йм#еда волкрои повитмой наодезнусу и душка ло седем кичей, кождрые рукя зозтвия матарь люблю и ви\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 111s 11ms/step - loss: 1.3492\n",
      "epoch 10\n",
      "argmax: бегой своей. и восстанут твой любовь, и сильных пиредних горькие ночи! но крепит душа дрой бестрава \n",
      "words_: холод восторгенный еще был прострамали, словко вокруг за всё на ног. это я сталый от него изнели в п\n",
      "probs_: йбу, я подысать был - сердарной бары проскролья. нет. от незручный и его отрома кошечта дрей придыва\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 121s 12ms/step - loss: 1.3163\n",
      "epoch 11\n",
      "argmax: лййййьт# здетони дребе е  . б д разлется пребрази скорбей скорбей скорбу! # кобрострарей! #  друдне \n",
      "words_: ались? и без жазды. она туманной страшно и меня, последкий головок был жизни новь, столь и встретишь\n",
      "probs_: что ты и порой прелесша заботы потоманский убледеет. взноски. взгляния, весилы об щеворгаю, мертанно\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 122s 12ms/step - loss: 1.3256\n",
      "epoch 12\n",
      "argmax: лййййе тезн. нез статил, та старусти страсть страсть. и страсни страсти страсти страсти и страсно. и\n",
      "words_: валияяи едала еес ядной винова силенье и шелку. не бойся ты в земних люблю от воле частала в море кр\n",
      "probs_: бесяя и минем. я подистое в любо и словье заплакить мы лишь ое отразлива насего так над с проргах, м\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 122s 12ms/step - loss: 1.2648\n",
      "epoch 13\n",
      "argmax: лййдпрел он одерленной различится друг, как месяц в тебя отраднувшийся снова над еверность сильных н\n",
      "words_: бегу, белело, под хрустале, где дреблю, и сильней души свяя чистый горят, порой и это поведели темно\n",
      "probs_: влйщйё#ти, евижспищик хребулет. так хриней, предвытавита, ее нет, надолг ! ночь людей, порой так, си\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 123s 12ms/step - loss: 1.2742\n",
      "epoch 14\n",
      "argmax: лййм е от ты светом и короно и встреданностья сини кровь похожи засыпало с души. но кредился на встр\n",
      "words_: моске свяжей круд! станут. # но моги засеты б яще не нах о знала холода дымы! ее под ней головой на \n",
      "probs_: лййм и тает мне ис кровь. постакают в рувекой! все жилы еще встремленья песни. не розовей, снова, св\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 125s 12ms/step - loss: 1.2489\n",
      "epoch 15\n",
      "argmax: лййм е о скалок добрю и слишась тум живут так неслышно обнимает, как месяц еще не станет трепеться в\n",
      "words_: ной туманно и окрусть моя мечта же, отсходиться не почальных нес. ни умела дух тревожной на заленых \n",
      "probs_: е немося - меня дошей ни спрут! только от любовно смели всталнок дверки, где далекие с там силой сос\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 120s 12ms/step - loss: 1.2712\n",
      "epoch 16\n",
      "argmax: лййм ни словом, сильней и люблю на белья. а ведь под нет солненной лужим в кровок - так несстную пет\n",
      "words_: ом. порошам они кормали блится, пущу мы тайдет забвенья весны. ничего. любовь и детей за тебе помню,\n",
      "probs_: ном, он томка за нимсеса, может онечека, присрость. а довнумысь витель, над лиловкали цветы зрадном \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 103s 10ms/step - loss: 1.2394\n",
      "epoch 17\n",
      "argmax: лййм ен об черный тобожных симфоной и в тебе на томительний мир от ночь - и \"правы все милой приду л\n",
      "words_: ет подмелками кровь у простовижик толодиться за тощел. подаль все весом соленой позвезном в частой, \n",
      "probs_: ков жетли еще всему все, и без забвенья она. тебе горят, то я мол, на мины все, и былого са, это буд\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 98s 10ms/step - loss: 1.2813\n",
      "epoch 18\n",
      "argmax: лйййммие оеи небочные цветы. все открые, если я покажеть и все га молчится напевы остались головких \n",
      "words_: лйййммие ее  едерецецец красоты - не перья своейь. душаься пусть все, и безмолным, смела всюду тай л\n",
      "probs_: но ожальши еще проснивей давно, над умори шепев свою люблю надо мною, тебе вырвать. в за вствую или?\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 99s 10ms/step - loss: 1.2318\n",
      "epoch 19\n",
      "argmax: лйймдеесто не старвенной малый в тебе давно, ни слез твоей на мустить она приникнешь так вечно не сп\n",
      "words_: во моего. не  ней тебе давно, ни мук я это не спою, только тяжел, и смотрета и тебя я вдамно стары, \n",
      "probs_: дели встала тоскол и любве, ничежно ни муктые жгзную девой скорбе его - там мне отом, как к нам сеят\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 100s 10ms/step - loss: 1.2362\n",
      "epoch 20\n",
      "argmax: лй мене сней. мне не прошел. # с жем великой жизни всё был пошел все радом вответа неразние стону пр\n",
      "words_: во им-лнена. так не мне иствозны, перед не страшен не уболост. косподных раздель я живу их пустыцы п\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs_: вет гороже хорним разлидил и мил и пять меня ни аервил и лих в подвостик, что мне шепомшию снездими \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 95s 9ms/step - loss: 1.2161\n",
      "epoch 21\n",
      "argmax: лй метерока не спою, что бы мигубок, и смеется. я люблю лилий голодных в томненит лежные рук. о, без\n",
      "words_: лй те отрава люблю,лили - на обылока неси нежные рук. # остамив в мире твои меня дрома, подами в тум\n",
      "probs_:  зовно срепелий зовет меня ты гилчами глазать, пусть дне ни соменся. # стону кородном виной. кто сам\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 97s 9ms/step - loss: 1.2178\n",
      "epoch 22\n",
      "argmax: лй меноот не соснугам и слились в молнины смыхалет в сердцах пепелос из развалиным страганым словом,\n",
      "words_: менье наподительной под местанье кровь, день просказило и не ты, истрадать безмозны все живут, так л\n",
      "probs_: дажные чужи. я люблю эта ты под ним поединохнною люблю, тем, что - они не пишу печам дене. снимы в э\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 96s 9ms/step - loss: 1.2370\n",
      "epoch 23\n",
      "argmax: лймм и так слезами грустала, все нет сила призвуться люблю на тебя, и так неслышно обнимается в жизн\n",
      "words_: ет отредних руку принесле на другий в круга твои воле утрашный тополо и не спешностит, что солнце с \n",
      "probs_: ная с знала печаньем, исть так, не владь над евонний мирчаптая идна, радути форто шепчет грозам в на\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 130s 13ms/step - loss: 1.2353\n",
      "epoch 24\n",
      "argmax: лй, ко почел и мне не страшно и сурене прости угалась, всё дуй забвенье красота. знаю полечанты, и в\n",
      "words_: лй, наоскамло на кортебельном внигана не порочные черные с углу, зачем в хрустале утрата в таманной \n",
      "probs_: ка, как сущурлу чужду в не очи кровь, а бегряле души. полнос из нем святой замещатали, она. мне уляб\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 124s 12ms/step - loss: 1.2394\n",
      "epoch 25\n",
      "argmax: лой наостранном луна. но люблшамби волна и как плетляю гороша богача, судьбою, полна поведе, и смотр\n",
      "words_: лой наостранном симельной любовных личей, в церпеньем дороги. я сумел в водцех цел мне мертвые отраз\n",
      "probs_: онь. а ведь, утепели в полутьмы, не тронули, бестечьи много - слушам или серебрье крыльями шебком об\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 135s 13ms/step - loss: 1.2232\n",
      "epoch 26\n",
      "argmax: лймо тоть не тронут никогда печенность могу и светы беллю. и смеленье пробудена, и смеленья крастави\n",
      "words_: вой твой души. но веделить, сетуя на тебя ден запот. то видел, и цвете, она же моя под небе от жертв\n",
      "probs_: лй мое освежился не днем бы отдажнешь свири капятоди, тажа притразнуть, как любится одеялая и воглял\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 126s 12ms/step - loss: 1.2279\n",
      "epoch 27\n",
      "argmax: лаской любовной лирикой? какой это мы всех борезуческой потокой, как месяц с целова, полесть соловей\n",
      "words_: ческой жизнь, то окрастлый в подердца мог к приводит волю кразиный избралить пригуда в сердце сонны \n",
      "probs_: мой, слова я? песнянуться и сад кругом другая и помочном разораменье ясять я таинственно милых мести\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 132s 13ms/step - loss: 1.2014\n",
      "epoch 28\n",
      "argmax: лай, и смелей, сека светлая, и смотришь - цветы это ты же ты светом и слово, невезды безучус не все \n",
      "words_: евыю кинцем. - всю напев синей, мене передникем горя, на цепенность песни, дедов не винущей болоски \n",
      "probs_: ский меня насетдала, так волмен, и безупят сверной свитсна, если б мог сужира, меня вождя на знать д\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 135s 13ms/step - loss: 1.1976\n",
      "epoch 29\n",
      "argmax: лайти была была пладает твои больше осотовшись в забвенья, в сердце эти все овечьи вычески в траве, \n",
      "words_: ской не очно почка? но обвалила, как любовь моя и меня. люблю полосами я лучий как волна рассудитает\n",
      "probs_: ламчанный слышные ли? на только пятна. но люблю влетлевным. путь, семь и по ворот и в годи, у нем по\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 131s 13ms/step - loss: 1.1491\n",
      "epoch 30\n",
      "argmax: ла вдольх. в трепетали богишь полеский страшный с пророчный обмало тья под ней! без под угол, о, душ\n",
      "words_: ла вдольх. в нем там гасную на замолкть я помничь к стату с тобою, и ударой кудрястолько друг на бле\n",
      "probs_: лятво и, окриво у некого, что бы лесли мои. упадать и отвечая на колно вличья, но обержиные рук, и п\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 132s 13ms/step - loss: 1.1483\n",
      "epoch 31\n",
      "argmax: ла вдохне не смоятся в глушь и всех морей, что моложны, всё белый в тебя отрадать, в тервый страшно \n",
      "words_: вой любовью без этогой, на забвенья стохов. и за не станут ты - и смеет корость! # одая голодала бы \n",
      "probs_: лавые грудь не мном словесть, и, и и смоерь среме невозгу, и и стою-почь любовный к ни усекой под. о\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 150s 15ms/step - loss: 1.1347\n",
      "epoch 32\n",
      "argmax: ловки вдруг явилась на все не осныю скорей тебя не спою, и смертном сердце богана не этот сверкая ве\n",
      "words_: вой пригуба я, слуг послед. по ней безомна, уж путь я стару и слезительном горески, и под уменном дв\n",
      "probs_: ная, видала с припуться разостник ниспудь. но любям шолочный мире растова. это есть любовный менять,\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 124s 12ms/step - loss: 1.1365\n",
      "epoch 33\n",
      "argmax: ла вдрыский соловей там приместь под ночей безмозны я послем. все открытый в след. полесками идепла \n",
      "words_: вой любовь, но к упризную забвенья преду далеки разомил, и словом, и не поздали, мы встретит засвень\n",
      "probs_: ело впеночье устен попелыв пошел ис хравасти расплакли головивший она покрыль оду человечав в моится\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 126s 12ms/step - loss: 1.1269\n",
      "epoch 34\n",
      "argmax: лавым дедов и сила любовь, похожая с другом силах в остропат. ослыше я не спеть моя моя часочно пепе\n",
      "words_: ет мы смеленье словым столость! мне страстно с прастит любовь моя другом. когда грозит от печали у с\n",
      "probs_: ны пумнозла наслепали идущены - тенки жилей сакробу весне, ни чуждые не праздно и чертой до ча кино,\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 141s 14ms/step - loss: 1.1200\n",
      "epoch 35\n",
      "argmax: ла вдольше забвенье и страшно, ниднные красотой, не виреневию бессердце полу в забытые буком сиди. я\n",
      "words_: ский раздуличили меся-ты будут над нами сиять! но следной любовь, по ведь к небесать кородни, ни ког\n",
      "probs_:  в огих вен, невесто нарадали гула поночные так, что кажетит безумные глубинет пусть дек, слидой без\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 138s 14ms/step - loss: 1.1136\n",
      "epoch 36\n",
      "argmax: лайзщеся на тене светом, слишкомы - не вир. блестки свете поссудье страшно смертами шепчет дону тахо\n",
      "words_: лайзщеся ль речей и далей похолоде и я жду я люблю, и облаков люблю полосу. те под воде и бредел! ес\n",
      "probs_: ное не громами шелчку мне головой, дяшей среди счастье друг, вобря на ней! беспозна. ни моей золрце \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 128s 13ms/step - loss: 1.0977\n",
      "epoch 37\n",
      "argmax: лавком твоего. # но мечтанья и все стану забвенье и волна так лестницу я стадает снова не под ночных\n",
      "words_: евыю кудри твои горесть к прославот травегой горьком беремом и корокая она в дельше с розовым, и к у\n",
      "probs_: валия, влюбины прохластли прочку! и, на ледних ты, не зоватем, и светов! хде беспреко тебя, как хвор\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 130s 13ms/step - loss: 1.0968\n",
      "epoch 38\n",
      "argmax: лавке снавом стату я люблю на бледнеющей шири в мука не остыло в сердце без забвенье от людьм дверще\n",
      "words_: лавке снавом разлялинаонм евелая в твоей добри я люблю - остерного моей не спешу . и душо как весь б\n",
      "probs_: лой и шем смечт погоней - припиты, цева корпеоть не утиха и в лесчах вробевьи дошн, боль он с лишь у\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 137s 13ms/step - loss: 1.0806\n",
      "epoch 39\n",
      "argmax: лой солнца, как распер. все, чем терель. может меня! еще на берегельная могууми, на миняй! и смотриш\n",
      "words_: евы бездной. все житка и не так неслиткой грустью горят! мы я будь, в головой. телевы полусвет-полуг\n",
      "probs_: лавчко ладаном руки? о, бесто черные мурцакши разостнавшах ра колеткой сарем. так краткий так где ре\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240/10240 [==============================] - 146s 14ms/step - loss: 1.0848\n",
      "epoch 40\n",
      "argmax: лавке словым абблу как страдное эти листов волну откудах, как в жизни пробудила и возвратила мне пощ\n",
      "words_: лавке словым нег. и, пророчет мне отвазном я плен? руди отразных легкий горяча, ни вечный запланный \n",
      "probs_:  своомнитве. я мольитьям цветет в сердцан, этих чуже утеха в чужглу, и ж звездом. сквозкатишь он уди\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 147s 14ms/step - loss: 1.6852\n",
      "epoch 41\n",
      "argmax: ловлййм-кмкио может мое още моечной лежали тух, как местрепетна не мне не похо хо раз о иллл  оси оч\n",
      "words_: рялээфцц-?ццццццццццццйэ?цжццццалоаааее, льюбся, какая предо части берегуходи. залека пропуть слежны\n",
      "probs_: ловлййммдхмохыххогою мнехна. в ленуты, об глюбится в воде дел, что нет. не горогу я мир. в таме гове\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 146s 14ms/step - loss: 1.9954\n",
      "epoch 42\n",
      "argmax: лодки забвется в молотой сеперья, в полну. что мне брестл и спервелными уста, и под мусною ты. # сер\n",
      "words_: лодки забвется в горосках зады. но люблю молца готовей, не полногов в отбять и волну откудах, зачное\n",
      "probs_: ловке разеаяе!!-.    ооооохьсекрашах, захлих делямнхошизы дей тону, н, удил мы всен содни мучили в в\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 144s 14ms/step - loss: 2.2200\n",
      "epoch 43\n",
      "argmax: ли я стеку. # серах без тысной свою - смелиться был волшебный слеплиц цвет. ты уж тайде без под моиг\n",
      "words_: вая, подняюных прадома всё притразоветь, мелу же тамни не приняться не притвождяну, принесрастиней, \n",
      "probs_: вал я  часских к ты, тем блестки ты чашо бесста - сирепит мутрать-похницак, пожком, не будет, над на\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 152s 15ms/step - loss: 1.9785\n",
      "epoch 44\n",
      "argmax: ликикь мне. чем божта, из погоди - свину - в небя - то же, чтожеки - тот мир старой сил. погожишь во\n",
      "words_: ликикь слабый сил? прижит тервый подаль! я об гордал цереще тет не могу - я завлю-колчать в туман о \n",
      "probs_: на, не стрня так потовей. но нечки и залеплиневшьси! я селах, я в поплознустый свирнем зов тет, не в\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 142s 14ms/step - loss: 1.8220\n",
      "epoch 45\n",
      "argmax: лавквк ирывском латот живуще бездек не спраснием пратнок. но не спою мне не сил. когда жашаль пригов\n",
      "words_: лавквк ирывском многиешь в хрево вздали бесстанствое раеском сил. призамни заглаших сепенья, не утро\n",
      "probs_: лик. в селдак друг й тебзань поковась и доро. не дашохнейщих, когда жалей над наравилин  елччкуали в\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 145s 14ms/step - loss: 1.9655\n",
      "epoch 46\n",
      "argmax: лодк, и салицый в руве, кой безвнойной головом шова и в туту в том. но отова не в белейет ходила ты \n",
      "words_: лодк, и звезды и я погоща все аблаяет ы  . е, пусть белстенной синева ет моря глыхов и к теля тогда \n",
      "probs_:  все хоть жичкох рудвил я цвесей этом, двили кровсяви оду забы спада хреотиный голосо горобт на сгор\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 139s 14ms/step - loss: 6.0256\n",
      "epoch 47\n",
      "argmax: лклйцххемм м м        в вд  мк  и уынук уадаквкен,вем еу унеееннене н,тноен, д,о н, д,едд,зен,нслеет\n",
      "words_: лклйцххемм м м  я  кк с к и с не к ла ввяоон, веенас,  а и еее уомомзкд ероод аниоен, те сти пмене л\n",
      "probs_: авыячч,    св тов св  в с    с в и  н лое нся  нонно  ме в то н еноеентндд, т,,,ыееииыя ивыиеиперые \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 148s 14ms/step - loss: 4.7049\n",
      "epoch 48\n",
      "argmax: лкххи  д уви з д  в конв с  с с с по снни  о сн ки внно  ее     с в др озо      нот тнт т т т т твт \n",
      "words_: е, чхужет? что каз скузы быщкой - в извеярихаскенст нратнуие т т  нет т    г по но тст в у тт ,от в \n",
      "probs_: т впо этот. и всо час я стрыдо срм ст отпуигтбеп н нуевниеретиваокотумтд и ка д мтлл твемзое ртро но\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 3.8182\n",
      "epoch 49\n",
      "argmax: ложххх  лл  сс   с    с  огы  со но но с со с оно  но  с      но с  ост   но с  кое ны   не но но но\n",
      "words_: у ж жгшать наше трдые,тот й    ке в г  и чо тогто но дое оно р ко то ро з н ло до й по с ме с да а к\n",
      "probs_: вадчлх  олбоа и каебнн  беигд я, дуейранилннуиои вы сшоггзр еойо йяняде,лоше,иовтсыл  ейигнхийзеткй \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 164s 16ms/step - loss: 3.5574\n",
      "epoch 50\n",
      "argmax: лейххх тв се  но  ст у се с со со о сто с со сс о с с со с со с с со с со со с с о сс со со и ошехе \n",
      "words_: ва яя о  мо о  ту   че ко то мо а б не со по то огушя  жжжжжца вся был поже бралиолазк й и я о де и \n",
      "probs_: ы дожды го зазожем жжжце жис божегой мечияеачцс,рм пу бнос пацее о,наро ч оненле нывудчнеча ва тзои \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 116s 11ms/step - loss: 3.4774\n",
      "epoch 51\n",
      "argmax:  в отм и глде ы п не нол нод да не т не т не на не но не но не но но не но но не но но не но но не н\n",
      "words_: х ожиязыя, приг в борегуннуд н но а мо я  в в о тн е не и ноде но годе не до доде м но п но и но в в\n",
      "probs_: , с жжнюе не погуий в  жожи оте тольше зорте бершельаиеигх л, вшиза дхвй очыктлей б с га,ле асбуксмр\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 133s 13ms/step - loss: 3.4067\n",
      "epoch 52\n",
      "argmax:  в мия позоль жже кь жже тожта же тожи и жижет. # нежно же кале ногсси н  с не нед де не сн с не с с\n",
      "words_: ва нев сн д  с це  не не л п  к р в ч з я в де в м п де к ле с к е в н чно й до не не я те не лоде л\n",
      "probs_:  пылегохорресе ле ск зя,екатсса ги  и мербалеутгбеа вл в кря пн п валайоояекскрыласодибн дае сти тна\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 136s 13ms/step - loss: 3.4267\n",
      "epoch 53\n",
      "argmax: ет но зел. и не зазоть нал ее нннцц    пе пе не не пе к  пе пе пе пе пе пе пе пе пе пе пе пе пе пе п\n",
      "words_: а сыоык с о у у п с п в т н в е г к т бо с т е в к т ло ха ко ха пе те на бе ме с о а ме чи то и ч и\n",
      "probs_: ваи лжеийуйнихлный винел ноя он х й,  тако ний ушидкалаеляк ки взмсам,еп ку, уе пе ле пой пойамла ие\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 122s 12ms/step - loss: 3.2858\n",
      "epoch 54\n",
      "argmax:  в таму ивра   т  м мо ве о ве о ве о о о ве т о ве то те оо то те во то то ве о те те о о то ве о т\n",
      "words_: , молоко преждьце жей простовь. и ковостью брет. о сводном бесть стрь поротовь. старетнем иее гете д\n",
      "probs_: , # емть дря,итнадаечно т брызабе лекаядаов, к  влитя т и ши те, родма я дро ресстас тиме вуыбо в ем\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 126s 12ms/step - loss: 3.4959\n",
      "epoch 55\n",
      "argmax:  в зазв со олодоваж н на зарук е    т тт тто то тоо сее не ни вожца как проске то те то тттол то тол\n",
      "words_: е то тр ко ро то по отормотс мо кол б умо е не моле то то ое зе тото ти чтпые чо с к лоо ко ро хол с\n",
      "probs_: ре неиноло тткое нотозтнрузммнрнтелоочимыр пдцем, меолм ыоц в олрк волотме е соластмоло охлал елисиз\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 148s 14ms/step - loss: 3.4484\n",
      "epoch 56\n",
      "argmax:  в зате те со на на на о на не на на на  на о на о  на на не на и на не на не на не на на о на е на \n",
      "words_: ске вле н та на ра аооте са с са о да ко та ко я па т ла зо ла и са ба у са жа та да уе же чоо ле ба\n",
      "probs_: я егонжати та о коласу пенойянейяиткыне, те,ттаик й еййплажаснос сешкасиери ешуопод етци чорле е с л\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 128s 13ms/step - loss: 3.4020\n",
      "epoch 57\n",
      "argmax:  в заре в то но не не ве ве ве ве ве ве ве ве ве не ве ве не ве ве ве ве ве ве ве ве ве ве ве ве ве \n",
      "words_: ске в ути утри сей забое те ее м ко с те и п з не к де те ле о ве г с з не з я и за те отне хо ие ла\n",
      "probs_: сяй золцеленны аоаняци нелия гдолоечсат, ня лтдеаожанемок ры богй вк нит йа в дрлуи еи литан нолмлес\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 102s 10ms/step - loss: 3.3985\n",
      "epoch 58\n",
      "argmax:  вы жуши я мне не шея, трочь, и пе о о во овроду пьгоже велетнотосно с о ооо о солоо о о о но но со \n",
      "words_: я и нелой залек к о ро во со оо бо но  нехахно г оо то жо воло ни ы кажепо  назз омжжи спопоть. ть п\n",
      "probs_: ем тетрно гепгреро, корерозебеоненорди дой усо но дожатой неладялнячсво, са ко дерогосяожодушря пижо\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 105s 10ms/step - loss: 3.3495\n",
      "epoch 59\n",
      "argmax:  велей пиа  нео о пе  не  ор не не ноо не пе не не но не по на п м но ни вы зазозы вцалежижы вежишь \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_: х мвзузровяжно жих кожейко не грорье водилом. к родцеце бепели еоно те ло на сее го е пе вреднаты бе\n",
      "probs_: лоее, уваркрепигоии п чуолнейс хая ицнуз, з жтсдику носы иро лит ни пу вукиз я хакосы зоочаоо вые ло\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 104s 10ms/step - loss: 3.2749\n",
      "epoch 60\n",
      "argmax: ет   ы  о пожней весть не попо омни пождалеко веде задыл, яз цспепи на жи    в  вв с в овооо   сесо \n",
      "words_: да стреза неслди  л зонай взушне заспрл цсо н  зссс ссссс  ясооо то о лотеллло соллнннеле,  ла толок\n",
      "probs_: а  иемчрсинбп,ии,,есн,а есиопй е р ирдпнйиаинеи иеы енлвлм  стениреонл,яйеед ел тлтед сдпадивт, рмни\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 134s 13ms/step - loss: 3.1632\n",
      "epoch 61\n",
      "argmax: е не д  ннжко вожаль не отовья в посторазн                     ов  о о ооо о о   о о о о            \n",
      "words_: неш о бче ке, задо о не озвожая ходны не мивййяи что моло любовно ты не дезо не а час й. п т авчж че\n",
      "probs_: лее чсллчюштудь чат сеокоохмо  зочс ии оги   мзврдая уодд  к отавидлсы оеербоеоро о д дселг рбы нтос\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 145s 14ms/step - loss: 2.8789\n",
      "epoch 62\n",
      "argmax:  не вера в     о о  а.амехорт вочнить вель на ле о       оооо о  каповшожно не на ти          впрожн\n",
      "words_: о увеле я заозву а я де морна моо к о й у  ао чтрдов свочнежной тольбо цвя сомны - и и трель коре до\n",
      "probs_: я ин я в лита мегао овгдь зачелв. и обыл ночнозь м бов аеждс! саменна я! ак ,аий.яр заныйеч позаресм\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 112s 11ms/step - loss: 2.7004\n",
      "epoch 63\n",
      "argmax: е па сеуза стол. но в пе сто моче сто ве цеоты проле не сто солько сорга сто подне сомны поло не сто\n",
      "words_: е олея без чозмере - соле что светы вора пь корет лело нем звжна  у голо часте ло тами ча чгоже вест\n",
      "probs_:  ива кесто тий, на пищьк,л еночией. борсжасит. на бовхдо кувек. лечело ей бочальвы  влех, аветы толь\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 112s 11ms/step - loss: 2.7171\n",
      "epoch 64\n",
      "argmax: е по польши и в и в пол на ле сже йас сс   ссзазабе поз зазепе с созце поль о столькько поде презе п\n",
      "words_: не газаи жеть бели ленк лоты брез пазе крежити ласс казну порет. голь беле онита я сво слез чезней! \n",
      "probs_: , прустыелят сактахнст сасяю, и люблю - # зы зеря, олвевозо линаде сала ролрруватьтеешуй, льх петнал\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 102s 10ms/step - loss: 2.8371\n",
      "epoch 65\n",
      "argmax:  назт з   ш зтз нз ча е жае не по пе поле нет нази н      зо зз н на не незите пази в               \n",
      "words_: лйй ено  тов вебе о те на мее е о н п д с . ла с де мовна это цве за жеоц л б нш зс о з гео хак же и\n",
      "probs_: ше илиетов, нияс, роть либ пок мручт. слюбв не вое  вожанней эуздуль тошвер внегах я веду побяв, нев\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 109s 11ms/step - loss: 2.8502\n",
      "epoch 66\n",
      "argmax: е по п бризбжцкой в нель нево ню на сказ                                п   п         о  то х п п до\n",
      "words_: не уле уте то в не даль  к  в   е о з и и т о к .  м п с дз о  д ласа # и оло морозне дородо довь ац\n",
      "probs_: ле тинаваля ыелоисдант осерззезозле шне вмынах пранотттнй ун мытик калем отоиатдеуле, поззасти деры \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 117s 11ms/step - loss: 2.8592\n",
      "epoch 67\n",
      "argmax: е по рра ног не соленой в не на не веню  жета на кородне стрлень нежный не пе  зз ре ол литокоролья \n",
      "words_: е ув е в ало новь и не грей! а ж . , е на у и я ото тро не тев ш аты не мен брст волол зален радо от\n",
      "probs_: тслеш, нех н ковних тсклукн ео невц не нескомемя настот нз тенко побет втдунечн мериетны внот ке. ка\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 151s 15ms/step - loss: 2.7874\n",
      "epoch 68\n",
      "argmax: е по     з бз залозот пона во не ната оже не не пе не то на на не не то подо то не  в по нало потопо\n",
      "words_: не  заза е в  ве е оота  в лез же мото подоо еев то нев кове м  оеы се да бо то я подо и бе то за ча\n",
      "probs_: ми кон вго палночшпе, дай, # то киеспвети!ити неряны ва гольеррвевхо веволаятш нурвед цом ражавымыбм\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 141s 14ms/step - loss: 2.8883\n",
      "epoch 69\n",
      "argmax: енн    н     па ь   на о пь о  та  па по на п т на о совонооа  тота тота в   рамоа    о о но на нитт\n",
      "words_:  сео  л  ла е и з чо л к л ю на оц но о  д по ла саноноа сооона о ссите мо рат в н , с и   я ч в с б\n",
      "probs_: екоттмсум ур а , я на ст рох . яи берх ря йурмновето л ьиколнсбм,ньлвв кыйемрл сечабкуро к ь.смьабмр\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 146s 14ms/step - loss: 3.1061\n",
      "epoch 70\n",
      "argmax: енн  е е п пе не  с с мо па в мо п т  не пе е ве е о в на    еееееееее н пе    ь п се   о о о пе ной\n",
      "words_: . бе и е ве те х , с ле сель  б ре и у ре ве ли х и у не ут нен т  и ч д ме по т  у ы неной и о пем \n",
      "probs_: огбеенылуи чин, нитозийо. и моктга- слднтевессиатес чу а очепит, нклоак  вебоозки!  д   внея бь к мр\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 134s 13ms/step - loss: 2.9482\n",
      "epoch 71\n",
      "argmax: е        ю                       п            жа  с сот п т с те п с   ов # # в п в в з паса  а  ве \n",
      "words_: с в а  с ж о  у и  н л н  и т  о    к р п л с и  ж н   п б к н м в т   ь к н   к  а м м т я м й с , \n",
      "probs_: срьвсн аьон т й ти ьехлинялйвьи зк лолетлнз еывллеа,тна, ч дгн кетьпкс яикр уовноята ,иоуу леердмга \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 153s 15ms/step - loss: 3.1670\n",
      "epoch 72\n",
      "argmax: е           о н о не           не          не н  не не о   о  о на о          не не о н н не  на  на\n",
      "words_: де с е не ь  я г о с н й я , и л н  а р т , д с е а т   а п н е ж  л а е  , д те р м м х ш р а  о с \n",
      "probs_: е оеаеу ли а асх млураное м ку,аилиен й  уеяльксосньзови гвежепдшидыааова!е,,з сг  ся ло ье ноли на \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 144s 14ms/step - loss: 3.1312\n",
      "epoch 73\n",
      "argmax: о оо о с с о о но оос оосоооооо со со по о оо оо оооо на оо оо о оо оо о оо о на о но о о оооо оо о \n",
      "words_: е ооо ко н но ы по оосоооо я ч т зосо зо ь ло ь с я по бо е и во н у о мо  чо ро то го шо поо у ноо \n",
      "probs_: едиом!ое сугсве пал геспцаоют сл ч табядгбнкиныил зразле ранроеломаидпной текзбими пы.яракл,начако т\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 171s 17ms/step - loss: 3.1272\n",
      "epoch 74\n",
      "argmax:  в   н н н н н н н н н н н н н н н н н н н н н н н н н н н и и и и и и и и н н н по н с т с с  н по \n",
      "words_: и л а д ч д л о р д б г в й ю ь и и о с е   н х чи н п с с с к  б н  о н с ж л л п  с с  ы и с . у з\n",
      "probs_: дутылеьеетаннипаизиу, мыеаобдвсюыовотмом. ил жулюнцуами   леинлздта зе ьиес ам ам нимвл  я шлах ре о\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 171s 17ms/step - loss: 3.1573\n",
      "epoch 75\n",
      "argmax: о пе  с с         иелес пееее  е  е  е  е  е  е  е     е и      е е       еее             се        \n",
      "words_: е  п н  а м я й ие не д ле  е т с й п не ке о т се иееееее леи нее пе  . ке ь с л й т с и з ве бе е \n",
      "probs_: едожу сь нушсдо вр наты мтае уй аылев  дес во я с кевсбх ! лребоаалочто.ка ьи л псласеы воты с рерыл\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 130s 13ms/step - loss: 3.1186\n",
      "epoch 76\n",
      "argmax:  пе  н н            н   н н  н н но       н н но но но н     не н      н  на но на не на н  н н н н \n",
      "words_: о с  а  б а  е и . ц м й у аене сно о на ва с  о п е о  о б а о  п о  с о и д г  до н б з ,  но   т \n",
      "probs_: веяб йюбсегтне  део, шимл натаваупнядаге ь  гон. кавя леиоимр углуб я вмоимит илоса   ,г жушьмов   й\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 119s 12ms/step - loss: 3.0542\n",
      "epoch 77\n",
      "argmax: оо                      н н   е н н   е но  е но не но не не не  н  н   н   н н но но  е  н      н н\n",
      "words_: сн я ее пе м к о г ь н ч т й ь  о о л , . по ч  в а е , ж ю н я с , ее п н й м  п с и е р з ч  м ь а\n",
      "probs_: лшп.л  но иаоякечьяе зыену се оу ебнрнои ст ц утр шож огелиу итала новдеоедаложлршу на  и к н ер у н\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 125s 12ms/step - loss: 3.1227\n",
      "epoch 78\n",
      "argmax: оово     в в  о тозо а в в сос оззо в зо в в с и ссозоното ножь по ионосо и в и в тоао о аово н и   \n",
      "words_: к н бв са о во во то еоо  е и го с в  п с м в  х де о в . к лоцто на еотлу с , , ь я к  г увво т е х\n",
      "probs_: ввасд. г д и мо я,ахйвайок урне сс,хоенуног вононьн лдка!бта е вы  о нврхкнокажы иис ейьз гонря воцж\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 133s 13ms/step - loss: 3.0837\n",
      "epoch 79\n",
      "argmax: ооооо! !    о  о  о со с со по о со п п по    с с о с с со но со с с со о с  о с  о с  о с  о с  о с\n",
      "words_: е ооо ы р по с го по с у о ц по е бо а но  но во со  во с  мо по ео по я со ло д р во л   к у мо то \n",
      "probs_: аур ыо мяя мо аей ое арл веевел паюпося н сом  яср ле кгю у в  ао й  ау п о  т б дны, сиеж т з ов те\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 136s 13ms/step - loss: 3.0840\n",
      "epoch 80\n",
      "argmax:  пе  тее  ее вевве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве ве \n",
      "words_: и в йее р . т ж м с с и о е б ч жь в к т м к и ут  с т зот во коее  .о н а , ч  ж ле   е т те ре о т\n",
      "probs_: риой ш,м  а й мартри ст пле, н г д ншдолог, бу. ок аз р иводд,к аааыосх ни учес к мияо отжьух нпяр,е\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 124s 12ms/step - loss: 3.1292\n",
      "epoch 81\n",
      "argmax: оон!!ин  т в а    п моно то поо о и еео о о о о ото иошо о ни о о нонннна но номото и ивововопо ос с\n",
      "words_: гони ло п д р по оло в воиозо е г а но во и й ,  но п но но и р в ко бо епо и м х   роор о ш к д л н\n",
      "probs_: оово! .. и м  ме, орокрвкошйрриотиюотл,твснбкткнсеиихтрк во р  бмадлоескьо ж в  лилсоолол твотвяб,но\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 134s 13ms/step - loss: 3.1575\n",
      "epoch 82\n",
      "argmax:  па      еое ва е о      е ееее    незното со  а о      оо е в       в в ва о в в                   \n",
      "words_: по ро с е п та , т б к е з , ва сен в ч к к в ре и к и па в ча о по ноо во и д м п де о и  е  ра я ь\n",
      "probs_: возцнтаогг лыкьжвеавытндолепвеоя т с к.и ич вка саяпепюейапю ет  бул,одолав ерьасчяатц зо телмо у се\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 135s 13ms/step - loss: 3.1595\n",
      "epoch 83\n",
      "argmax:  по       в       во  о   о    в в  в        е                            о                  е      \n",
      "words_: оов в о ,  л ро а к  м  с а н о л я . , о о , к в о н б с в т с ево д то в т т то и с и  ы п и ц з  \n",
      "probs_: нреиомгккпл й  в дь яхпнпынбеждказннд лыбо лы, шююивтюторьннтпыйоядг вл бий таяи вишали оотоокрвоаин\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 145s 14ms/step - loss: 3.1286\n",
      "epoch 84\n",
      "argmax:  не  о  о по п   т  то п   в    о т н  но но не не  и з т     но ноно  п     т т о но    т          \n",
      "words_: то ке я уца ы ре е пе ато в н к о у в с . л е н и ч не й ан от т  в  п о с о о  уе от с м с о а воон\n",
      "probs_: нитйтеюбсотб к жьййьвмчкьлоо.уаопх в собачслно евыскоиокеямптвар  гувчпигожю  явоми тло аезтевызн ча\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 132s 13ms/step - loss: 3.0902\n",
      "epoch 85\n",
      "argmax:  соненненожожа о н тота о натототота но о н но о н но о н но о н то н но но но но но но н н то н н т\n",
      "words_: неноне пено нево пае зо мо вот итот на да го тототототототототототототото ко # е ио ве  е оннн н н е\n",
      "probs_:  бомтбюпнжл всцнцуйкаланик сиьяр ар  счалмь тойы азх рзли, то адсельиссшаршслусьрчеррлсй п ч!тми рй \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 148s 14ms/step - loss: 3.0113\n",
      "epoch 86\n",
      "argmax:  се   т        н    н  не не но не со в во се с вост в в в в во си сео не  се с о ст сэвесссссссо ст\n",
      "words_: не  с в ко  е ле с свво воо ло не и с че по то у го  м до  бе ко и но не потт т не н и восно на не г\n",
      "probs_: инсмл,ее р арйы нре  п иш й стонпрбйлэаи мислуйирослне ,вауе влюмаев б   ркбд  , н т со,ул дь ки ткн\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 176s 17ms/step - loss: 3.0208\n",
      "epoch 87\n",
      "argmax:  пе        о                                                                                        \n",
      "words_: а   с , х б , т с х ж неж ж х поте ме ле о пе но по ко но е с я етот во ое мо ге ге   кое ре се о о \n",
      "probs_: овня члзнсвлм,,ивогнибмуниналеяивьсноллощбаяхява иееопн вдт вугитедацнбрии.зввлае вев р мльтош!елев \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 144s 14ms/step - loss: 3.0113\n",
      "epoch 88\n",
      "argmax:  по                   т т   т   п т м мозе  п    т  но но   т    о эн эт эт    но  то н м но то и и \n",
      "words_: оо ! е   и р но то во де о # то о л щоо ло то мо о то но со м ше и у о й ре в то  х о ко , шо от в п\n",
      "probs_: шко, пк ллиааонуайм ктр, пвемлу дис еле слогмстит, -нврмуомейсаледез янйс вы м, вном я топнечйатаиви\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 11961s 1s/step - loss: 2.9646\n",
      "epoch 89\n",
      "argmax:  по  н   н не не   но             о н но  н  не не  не  не  не не   не  не о  не  не не  те не пе  т\n",
      "words_: . ро ве ч к то то зем с е м х же # ст пе че бе не в и ае эе ре м немо ремо - та ко - то де не уто у \n",
      "probs_: нмооесл лтс  д нбб,к, мцедабочоусей , г ас дол стел бямяан.нарьпмлмикобышьснс з нр о слыган езок ле \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 63s 6ms/step - loss: 2.8878\n",
      "epoch 90\n",
      "argmax:  пн   н  ж   н   не       не н нте не не но не не не  не  не  и в не   но не  н   не  не не не не не\n",
      "words_: а л  ч т г в м е  я и де  е пе че , в се к а же  г я се сто ле - # бе пе е з и ко о сте сто пе и вал\n",
      "probs_: симн,бк бу лупшса тодевгот зовны, аррамтвалыби нле мя  с рютьсмимь ляю пови и тр зсготонобнасоб , се\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 75s 7ms/step - loss: 2.8315\n",
      "epoch 91\n",
      "argmax:  но  нонот но но но не тет о не о не о о не о в во не о ве во во во не о не не не не но не не не не \n",
      "words_: я е . во х ст з зво з о я л те ле нт я по в во я мо я ло сто но во ла о я ке ао се я в го и во се же\n",
      "probs_: исотовжжтвцсзогыто ц ебн, до терввад,л в чи лая тюуимиев мрокый те дрилкли яечей, вапнц маях гошеоск\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 91s 9ms/step - loss: 2.8679\n",
      "epoch 92\n",
      "argmax:  п               ж ж ж ж т п с сотос  во      с  но  са со ва но не не не не не не не не не не не не\n",
      "words_: в  д г н боооцот пт лото же а но же моло ат т мот те жо ато голо по  ио че же зет ло во г но бо асе \n",
      "probs_: ос н  вз з иварсдрихнал чтзясчи у- дрыксб,л рьо # кетьнващнрдс ут ау,ьачив и трюх, п лотязе освак во\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 118s 12ms/step - loss: 3.0610\n",
      "epoch 93\n",
      "argmax:  п       н н не оо он нононон  н нос нононоон нононоонон ноон нос нононон  н н с оонононон  н н     \n",
      "words_: з м а г е о и е о не ве ле се е се ке и м е де рон го лон , н поне п ке а п доносоон сн носе е б с й\n",
      "probs_: овннет пи га ч,е с езрсталокыж, вешоте оыкь ьерснеп бетасче ез веск. бег к месч. пошьулд ови диб с!,\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 100s 10ms/step - loss: 2.9824\n",
      "epoch 94\n",
      "argmax:  п    со со со в т         о в в во    о в ц    е ва о вао о  о во  ц о  о о о е о о о о о о о о о в\n",
      "words_: мо т я до  в и з с т м д ж з х з в т в г г в к т пе во я с еева л с у а м лоо и в е ео м ко п гоео о\n",
      "probs_: ямрклсюмь ды ватдю заао па толиловцх нхя к,х ладеожулинирвртой пигнешния # ло доноз ду.алайедунасдуч\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 75s 7ms/step - loss: 2.8927\n",
      "epoch 95\n",
      "argmax:  с    но но о о о но        ст ст сто со с с с с  с с т  э с с с с  с  с с с с  с с с с с с  с с с с\n",
      "words_: во то по т   п  па  к то мо и а -а соо ло уа се на ла на не по по ло , о но на и бо о  но дото мо  щ\n",
      "probs_: гвсл нт ,рет вылк рни зехосьеврероля, ыт,от , уюцо  лока товезан,оя # окиштасавясаращоесв ипкуке ке \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 77s 8ms/step - loss: 2.8113\n",
      "epoch 96\n",
      "argmax:  по о н т  нт то не но но но но но но но но но но но но но но но но но но но но но но но но но но но\n",
      "words_: ло и т л  ло н в во ро ло по но то о о о о но по ко до тоно гоно ло яон мо чо а о и то но но ко во ,\n",
      "probs_:  нелорнав лт , ч зсжя с пиз скокр , дьни, дот во. ктри бени а  раеж.вс, тымкоир, но- сми нр,! хетьмы\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 80s 8ms/step - loss: 2.8137\n",
      "epoch 97\n",
      "argmax:  п о   оотото  о с    о  о  о  о      о      о о о и и но с  се но но сто с о сте  то но и о но и но\n",
      "words_: , с  моот еоо е я е ы со во н во  по я и по я  то но сте зе ло но но но - и жо ше по но о т   по и ч\n",
      "probs_: в дв,рпкмоябкеч пуей козь мьпрасижал шнычиенойцвы - желапе жава # у че пе нигно нас,, нычу жазнандин\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 83s 8ms/step - loss: 2.8257\n",
      "epoch 98\n",
      "argmax:  п о    т по но о о то ноо о но то о ноо о ноо о по ноноо о по но по  ноноото ноноотоноо о о о о о о\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_: пооо ю я се   еоао лооо о во зоо у ноо е то а м й  пе  т т и гто сто и и по и  ло по - се ве то во ж\n",
      "probs_: ркке папкаеокоакодоо  ьонде, нолонаноорм о сох б тоты.ну рру  х ватум иова ачовео  леснуляннизис, я \n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 83s 8ms/step - loss: 2.7719\n",
      "epoch 99\n",
      "argmax:  то  оттотоно во со о но но но но в не но но но не но но но не не но но не ноно но нон не но но ное \n",
      "words_: ло моо ь чотн новоэтотоно по и в дао го мо со до то в и что к до о мо в но ко но в ло ь мото не не у\n",
      "probs_: мокоовооьокррзмканошит новь й к ногкрра тетебовемо мой ноа, ик, ко ие путы, дредов ныг кой ттга - ты\n",
      "Epoch 1/1\n",
      "10240/10240 [==============================] - 82s 8ms/step - loss: 2.7577\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "\n",
    "gen = sequenses_generator(batch_size,seq_size)\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    print('epoch', epoch)\n",
    "    \n",
    "    print('argmax:',gen_string(100, False, False))\n",
    "    print('words_:',gen_string(100, False, True))\n",
    "    print('probs_:',gen_string(100, True, True))\n",
    "\n",
    "    X,Y = gen.__next__()\n",
    "    \n",
    "    model.fit(X, Y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save_weights('weights1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beem search\n",
    "Node = namedtuple('Node', ['state', 'chars', 'logsums', 'parents'])\n",
    "\n",
    "def beem_search(max_length, beem_count):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def next_transition_dist(node):\n",
    "        \n",
    "        state = node.state\n",
    "        \n",
    "        if state is None:\n",
    "            state = get_initial_state()\n",
    "        \n",
    "        char = np.zeros((len(alphabit),))\n",
    "        if len(node.chars):\n",
    "            char = node.chars[-1]\n",
    "        \n",
    "        probs,state = propagate(char, state)\n",
    "        \n",
    "        return state, np.log(probs)\n",
    "    \n",
    "    best_solution = None\n",
    "    nodes_to_check = []\n",
    "    best_local_solutions = []\n",
    "    \n",
    "    nodes_to_check.append(Node(state = None, chars = [], logsums = 0, parents = [] ))\n",
    "    \n",
    "    #\n",
    "    iteration = 0\n",
    "    #\n",
    "    \n",
    "    while len(nodes_to_check) and len(nodes_to_check[0].chars) <= max_length:\n",
    "        #\n",
    "        print('')\n",
    "        print('iteration', iteration)\n",
    "        iteration+=1\n",
    "        print('nodes to check', len(nodes_to_check) )\n",
    "        \n",
    "        #\n",
    "        \n",
    "        posible_transitions_from_nodes = []\n",
    "        probs_of_transitions = []\n",
    "        \n",
    "        for node in nodes_to_check:\n",
    "            state, dist = next_transition_dist(node)\n",
    "            dist = dist.reshape((-1))\n",
    "            probs = (dist+node.logsums)\n",
    "            probs_of_transitions.append(probs)\n",
    "            posible_transitions_from_nodes.append((state, dist))\n",
    "            \n",
    "        probs_of_transitions = np.concatenate(probs_of_transitions)\n",
    "        inx_of_best_transitions = probs_of_transitions.argsort()[::-1][:beem_count]\n",
    "        \n",
    "        new_nodes_to_check = []\n",
    "        \n",
    "        #\n",
    "        print('condidates', len(inx_of_best_transitions))\n",
    "        \n",
    "        #\n",
    "        \n",
    "        for inx in inx_of_best_transitions:\n",
    "            \n",
    "            parent_node_inx = int(inx/len(alphabit))\n",
    "            inx_of_solution = inx-parent_node_inx*len(alphabit)\n",
    "            parent_node = nodes_to_check[parent_node_inx]\n",
    "            last_char = np.zeros((len(alphabit),))\n",
    "            last_char[inx_of_solution]=1\n",
    "            parent_chars = parent_node.chars\n",
    "            logsums = posible_transitions_from_nodes[parent_node_inx][1][inx_of_solution]\n",
    "            parents = parent_node.parents + [id(parent_node)]\n",
    "            \n",
    "            state = posible_transitions_from_nodes[parent_node_inx][0]\n",
    "            \n",
    "            new_node = Node(state = state, chars = parent_chars+[last_char], logsums = logsums, parents = parents)\n",
    "\n",
    "            if inx_to_charter[last_char.argmax()] == '#': #end of\n",
    "                if best_solution is None:\n",
    "                    best_solution = new_node\n",
    "                else:\n",
    "                    if best_solution.logsums/len(best_solution.chars) < new_node.logsums/len(new_node.chars):\n",
    "                        best_solution = new_node\n",
    "            else:   \n",
    "                new_nodes_to_check.append(new_node)\n",
    "                \n",
    "            best_local_solutions.append(new_node)\n",
    "            best_local_solutions = sorted(best_local_solutions, key = lambda x: x.logsums/len(x.chars),reverse = True)[:10]\n",
    "        \n",
    "        nodes_to_check = new_nodes_to_check\n",
    "            \n",
    "            \n",
    "    return best_solution, best_local_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration 0\n",
      "nodes to check 1\n",
      "condidates 40\n",
      "\n",
      "iteration 1\n",
      "nodes to check 39\n",
      "condidates 100\n",
      "\n",
      "iteration 2\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 3\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 4\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 5\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 6\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 7\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 8\n",
      "nodes to check 98\n",
      "condidates 100\n",
      "\n",
      "iteration 9\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 10\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 11\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 12\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 13\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 14\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 15\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 16\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 17\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 18\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 19\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 20\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 21\n",
      "nodes to check 97\n",
      "condidates 100\n",
      "\n",
      "iteration 22\n",
      "nodes to check 98\n",
      "condidates 100\n",
      "\n",
      "iteration 23\n",
      "nodes to check 97\n",
      "condidates 100\n",
      "\n",
      "iteration 24\n",
      "nodes to check 95\n",
      "condidates 100\n",
      "\n",
      "iteration 25\n",
      "nodes to check 98\n",
      "condidates 100\n",
      "\n",
      "iteration 26\n",
      "nodes to check 96\n",
      "condidates 100\n",
      "\n",
      "iteration 27\n",
      "nodes to check 95\n",
      "condidates 100\n",
      "\n",
      "iteration 28\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 29\n",
      "nodes to check 98\n",
      "condidates 100\n",
      "\n",
      "iteration 30\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 31\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 32\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 33\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 34\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 35\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 36\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 37\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 38\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 39\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 40\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 41\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 42\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 43\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 44\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 45\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 46\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 47\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 48\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 49\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 50\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 51\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 52\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 53\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 54\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 55\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 56\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 57\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 58\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 59\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 60\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 61\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 62\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 63\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 64\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 65\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 66\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 67\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 68\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 69\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 70\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 71\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 72\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 73\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 74\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 75\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 76\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 77\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 78\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 79\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 80\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 81\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 82\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 83\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 84\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 85\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 86\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 87\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 88\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 89\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 90\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 91\n",
      "nodes to check 99\n",
      "condidates 100\n",
      "\n",
      "iteration 92\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 93\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 94\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 95\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 96\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 97\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 98\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 99\n",
      "nodes to check 100\n",
      "condidates 100\n",
      "\n",
      "iteration 100\n",
      "nodes to check 100\n",
      "condidates 100\n"
     ]
    }
   ],
   "source": [
    "b = beem_search(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_solutions = b[1]\n",
    "best_solution = b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ево  и к по нтээээээ#'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(best_solution.chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "евоо н в но то ной к и и о и о и и и и о и и и и и и и и и и и и и и и и и и и и о стой  -0.022791784 140551411271112\n",
      "евоо н в но то ной к и и о и о и и и и и и и и и и и и и и и и и и о и и и и и и и о стой  -0.026888177 140550983163976\n",
      "евоо н в но то ной к и и о и и и и и о и и и и и и и о и и и и и и и о стой  -0.023231965 140550983164240\n",
      "евоо н в но то ной к и и о и о и и и и и о и и и и и о и и и и и и и о стой  -0.026541803 140551410937704\n",
      "евоо н в но то ной к и и о и и и и и о и и и и и и и о и и и и и о стой  -0.029569559 140550983164240\n",
      "евоо н в но то ной к и и о и и и и и о и и и и и о и и и и и о и и и о стой  -0.031628665 140550983167144\n",
      "евоо н в но то ной к и и о и о и и и и и о и и и и и о и и и о стой  -0.029926872 140550983187976\n",
      "евоо н в но то ной к и и о и о и и и и и и и и и и и и и и и и и и о и и и и и и и о и и и о стой  -0.046468955 140551411272520\n",
      "евоо н в но то ной к и и о и о и и и и и и и и и и и и и и и и и и и и и и и и и о и и и  -0.04362992 140550983188416\n",
      "евоо н в но то ной к и и о и и и и и о и и и и и и и о и и и и и и и о и и и и стой  -0.04371597 140551411273048\n"
     ]
    }
   ],
   "source": [
    "for solution in local_solutions:\n",
    "    print(decode_seq(solution.chars), solution.logsums, solution.parents[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
