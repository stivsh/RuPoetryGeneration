{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from collections import Counter\n",
    "from get_data_for_w2v import *\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def loggin(*params):\n",
    "    print(\" \".join([ str(p) for p in params ]))\n",
    "    with open(\"log.txt\", \"a\") as logfile:\n",
    "        logfile.write(datetime.datetime.now().strftime(\"%I:%M%p on %B %d, %Y\") + \" \" + \" \".join([ str(p) for p in params ]) + \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "print(tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_emb_data()\n",
    "word_to_inx, inx_to_word = get_dicts()\n",
    "vocab_size = len(word_to_inx)\n",
    "loggin(\"prepared_text len:\",len(get_prepared_text()))\n",
    "loggin(\"vocab_size:\",vocab_size)\n",
    "\n",
    "def encode(prepared_text):\n",
    "    return np.array([word_to_inx[w] for w in prepared_text.split() ])\n",
    "    \n",
    "def decode(seq):\n",
    "    return ' '.join([inx_to_word[x] for x in seq])\n",
    "\n",
    "\n",
    "def sequenses_generator(data, batch_len, seq_length, randomized = True):\n",
    "    data_len = len(data)\n",
    "    while True:\n",
    "        X = []\n",
    "        rand_inx = -1\n",
    "        while len(X) < batch_len:\n",
    "            if randomized:\n",
    "                rand_inx = np.random.randint(data_len)\n",
    "            else:\n",
    "                rand_inx = (rand_inx + 1)%data_len\n",
    "                \n",
    "            poem_len = len(data[rand_inx])\n",
    "            \n",
    "            if poem_len < seq_length:\n",
    "                continue\n",
    "            if randomized:\n",
    "                shift = np.random.randint(poem_len-seq_length)\n",
    "            else:\n",
    "                shift = 0\n",
    "                \n",
    "            seq_in = data[rand_inx][shift:seq_length+shift]\n",
    "            X.append(seq_in)\n",
    "        yield np.array(X)\n",
    "        \n",
    "        \n",
    "def generate(model, max_size, sampling = False, pattern = None):\n",
    "    \"\"\"\n",
    "        use sampling of charters insted of argmax, use sance seed))\n",
    "    \"\"\"\n",
    "    \n",
    "    #add random pattern and sampling\n",
    "    if not pattern:\n",
    "        pattern = encode('')\n",
    "    else:\n",
    "        pattern = encode(pattern)\n",
    "        \n",
    "    model.reset_state()\n",
    "\n",
    "    last_out = None\n",
    "\n",
    "    for w in pattern:\n",
    "        last_out = model.step(w).argmax()\n",
    "\n",
    "    generated = []\n",
    "\n",
    "    for inx in range(max_size):\n",
    "        last_out = model.step(last_out)\n",
    "        last_out[word_to_inx['<rear_w>']] = 0\n",
    "        last_out = last_out/np.sum(last_out)\n",
    "        if sampling:\n",
    "            last_out = np.random.choice(range(len(last_out)), p = last_out )\n",
    "        else:\n",
    "            last_out = last_out.argmax()\n",
    "         \n",
    "        if inx_to_word[last_out] == '#':\n",
    "            break\n",
    "        generated.append(last_out)\n",
    "        \n",
    "    return np.array(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def rnn_placeholders(state):\n",
    "    \"\"\"Convert RNN state tensors to placeholders with the zero state as default.\"\"\"\n",
    "    if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\n",
    "        c, h = state\n",
    "        c = tf.placeholder_with_default(c, c.shape, c.op.name)\n",
    "        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n",
    "        return tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "    elif isinstance(state, tf.Tensor):\n",
    "        h = state\n",
    "        h = tf.placeholder_with_default(h, h.shape, h.op.name)\n",
    "        return h\n",
    "    else:\n",
    "        structure = [rnn_placeholders(x) for x in state]\n",
    "        return tuple(structure)\n",
    "    \n",
    "def lstm_cell(state_size):\n",
    "    return tf.contrib.rnn.BasicLSTMCell(state_size)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, sess, seq_length, vocab_size, embed_dim, verbas = True,  state_sizes=[128,128], grad_clip = False):\n",
    "        \n",
    "        self.sess = sess\n",
    "        self.state_sizes = state_sizes\n",
    "        \n",
    "        if verbas: loggin('Creating NN ....')\n",
    "        \n",
    "        #data paceholder\n",
    "        self.train_input = tf.placeholder(tf.int64, [None, seq_length])\n",
    "        \n",
    "        #1)deffine learning graph\n",
    "        #embedings for input data\n",
    "        emb_layer = tf.contrib.layers.embed_sequence(self.train_input, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            embed_dim=embed_dim,\n",
    "                                            scope=\"data_emb\")\n",
    "        \n",
    "        #LSTM RNN layers\n",
    "        cells = [lstm_cell(_) for _ in state_sizes ]\n",
    "        self.rnn_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "                \n",
    "        with tf.variable_scope(\"rnn_layer\"):\n",
    "            lstm_output, lstm_states = tf.nn.dynamic_rnn(self.rnn_cell, emb_layer, dtype = tf.float32)\n",
    "                \n",
    "        #Deffine truncated seqs for output and loss calculation\n",
    "        skeep_words = 4\n",
    "        start_position = skeep_words\n",
    "        count = seq_length-skeep_words-1\n",
    "        \n",
    "        trancated_lstm_output = tf.slice(lstm_output, begin = [0,start_position,0], size = [-1,count,-1])\n",
    "        targets = tf.slice(self.train_input, begin = [0,start_position+1], size = [-1,count])       \n",
    "        \n",
    "        #Output layer\n",
    "        output_layer = tf.contrib.layers.fully_connected(trancated_lstm_output, vocab_size,\n",
    "                                                         activation_fn=None, scope='FC_out')\n",
    "        \n",
    "        #Calsulate loss\n",
    "        input_data_shape = tf.shape(targets)\n",
    "        self.loss = tf.contrib.seq2seq.sequence_loss(output_layer,\n",
    "                                                     targets,\n",
    "                                                     tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        if grad_clip:\n",
    "            gvs = optimizer.compute_gradients(self.loss)\n",
    "            capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "            self.optimize = optimizer.apply_gradients(capped_gvs)\n",
    "        else:\n",
    "            self.optimize = optimizer.minimize(self.loss)\n",
    "            \n",
    "        \n",
    "        #2)deffine acc func\n",
    "        pred_classes = tf.reshape(tf.argmax(output_layer, axis=2),[-1])\n",
    "        y_classes = tf.reshape(targets,[-1])\n",
    "            \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(pred_classes, y_classes), tf.float32))\n",
    "        \n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('accuracy', self.accuracy)\n",
    "        self.merged_summary = tf.summary.merge_all()\n",
    "        \n",
    "        #3)predict next charter graph\n",
    "        self.input = tf.placeholder(tf.int32)\n",
    "        self.input_state = rnn_placeholders(self.rnn_cell.zero_state(1,tf.float32)) \n",
    "        pred_emb_layer = tf.contrib.layers.embed_sequence(tf.reshape(self.input, [1,1]), \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            embed_dim=embed_dim,\n",
    "                                            scope=\"data_emb\",\n",
    "                                            reuse=True)\n",
    "\n",
    "        with tf.variable_scope(\"rnn_layer\"):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            predict_rnn_output, self.output_state = tf.nn.dynamic_rnn(self.rnn_cell,\n",
    "                                                                pred_emb_layer, dtype = tf.float32,\n",
    "                                                                initial_state = self.input_state )\n",
    "\n",
    "        predict_output_layer = tf.contrib.layers.fully_connected(predict_rnn_output, vocab_size,\n",
    "                                                         activation_fn=None, scope='FC_out', reuse = True)\n",
    "\n",
    "        self.predict_output = tf.reshape(tf.nn.softmax(predict_output_layer),[-1])\n",
    "        \n",
    "        if verbas: \n",
    "            loggin(\"input tensor shape:\",self.train_input.get_shape())\n",
    "            loggin(\"\\t Learning graph:\")   \n",
    "            loggin(\"emb_layer shape:\",emb_layer.get_shape())    \n",
    "            loggin(\"lstm_output shape:\", lstm_output.get_shape())\n",
    "            loggin(\"start_position for slice:\",start_position)\n",
    "            loggin(\"slice count:\",count) \n",
    "            loggin(\"output_layer shape:\",output_layer.get_shape())\n",
    "            loggin(\"targets shape:\",targets.get_shape())\n",
    "            loggin(\"self.loss shape:\",self.loss.get_shape())\n",
    "            \n",
    "            loggin(\"\\t Acc:\")  \n",
    "            loggin(\"pred_classes shape:\", pred_classes.get_shape())\n",
    "            loggin(\"y_classes shape:\", y_classes.get_shape())\n",
    "            \n",
    "            loggin(\"\\t Prediction graph:\")     \n",
    "            loggin(\"pred_emb_layer shape:\",pred_emb_layer.get_shape())\n",
    "            loggin(\"predict_rnn_output shape:\",predict_rnn_output.get_shape())\n",
    "            loggin(\"predict_output shape:\",self.predict_output.get_shape())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def train_on_batch(self, batch, learning_rate = 1e-3):\n",
    "        feed = {self.train_input: batch,self.learning_rate:learning_rate}\n",
    "        return self.sess.run([ self.loss, self.optimize ], feed)[0]\n",
    "    \n",
    "    def get_loss(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.loss, feed)\n",
    "    \n",
    "    def get_accuracy(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.accuracy, feed)\n",
    "    \n",
    "    def get_summary(self, batch):\n",
    "        feed = {self.train_input: batch}\n",
    "        return self.sess.run(self.merged_summary, feed)\n",
    "    \n",
    "    def get_accuracy_for_seq(self,seq):\n",
    "        encoded = encode(seq)\n",
    "        predicted = []\n",
    "        self.reset_state()\n",
    "        for _ in encoded:\n",
    "            predicted.append( self.step(_) )\n",
    "        eq_count = sum( [ int(_[1] == _[0].argmax()) for _ in zip(predicted[:-1], list(encoded)[1:]) ] )\n",
    "        return eq_count/len(predicted)\n",
    "    \n",
    "    def step(self ,w_inx):\n",
    "        feed = {self.input: w_inx, self.input_state: self.curent_state}\n",
    "        out, self.curent_state = self.sess.run([self.predict_output, self.output_state], feed)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.curent_state = self.sess.run(self.rnn_cell.zero_state(1,tf.float32))\n",
    "      \n",
    "    def __deffault_fname__(self):\n",
    "        fname = \"statesize-%s-cellcount-%s-.ckpt\" % (\n",
    "            str(self.state_sizes[-1]),str(len(self.state_sizes)) )\n",
    "        return fname\n",
    "        \n",
    "    def save(self, fname = None, loss = None):\n",
    "        savepath = \"model_waights\"\n",
    "        \n",
    "        if not fname: fname = self.__deffault_fname__()\n",
    "        if loss: fname = \"loss-%s-\"%(str(loss))+fname\n",
    "        fname = join(savepath, fname)\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, fname)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "    def load(self, fname = None):\n",
    "        savepath = \"model_waights\"\n",
    "        \n",
    "        if not fname: fname = self.__deffault_fname__()\n",
    "        fname = join(savepath, fname)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, fname)\n",
    "\n",
    "    def load_best(self):\n",
    "        savepath = \"model_waights\"\n",
    "        files = [f for f in listdir(savepath) if isfile(join(savepath, f))]\n",
    "        \n",
    "        all_checkpoint_parameters = []\n",
    "        for fname in files:\n",
    "            checkpoint_parameters = {\"fname\":fname}\n",
    "            parts_of_name = fname.split('-')\n",
    "            while len(parts_of_name)>1:\n",
    "                key = parts_of_name[0]\n",
    "                value = parts_of_name[1]\n",
    "                checkpoint_parameters[key] = value\n",
    "                parts_of_name = parts_of_name[2:]\n",
    "                all_checkpoint_parameters.append(checkpoint_parameters)\n",
    "                \n",
    "        all_checkpoint_parameters = [par for par in all_checkpoint_parameters\n",
    "                                     if \"statesize\" in par and \"cellcount\" in par and \"loss\" in par  ]\n",
    "        \n",
    "        all_checkpoint_parameters = [par for par in all_checkpoint_parameters\n",
    "                                     if int(par[\"statesize\"])==self.state_sizes[-1] and int(par[\"cellcount\"])==len(self.state_sizes) ]       \n",
    "         \n",
    "        if not len(all_checkpoint_parameters):\n",
    "            loggin('No checkpoints for this model')\n",
    "            return\n",
    "        \n",
    "        all_checkpoint_parameters = sorted(all_checkpoint_parameters, key=lambda x: float(x['loss']))  \n",
    "        fname = all_checkpoint_parameters[0]['fname'].split('.ckpt')[0]+'.ckpt'\n",
    "        loggin('loaded from %s' % fname)\n",
    "        self.load(fname)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NN ....\n",
      "input tensor shape: (?, 20)\n",
      "\t Learning graph:\n",
      "emb_layer shape: (?, 20, 300)\n",
      "lstm_output shape: (?, 20, 16)\n",
      "start_position for slice: 4\n",
      "slice count: 15\n",
      "output_layer shape: (?, 15, 6631)\n",
      "targets shape: (?, 15)\n",
      "self.loss shape: ()\n",
      "\t Acc:\n",
      "pred_classes shape: (?,)\n",
      "y_classes shape: (?,)\n",
      "\t Prediction graph:\n",
      "pred_emb_layer shape: (1, 1, 300)\n",
      "predict_rnn_output shape: (1, 1, 16)\n",
      "predict_output shape: (6631,)\n",
      "[ 0.0001508   0.0001508   0.0001508  ...,  0.00015081  0.00015082\n",
      "  0.0001508 ]\n",
      "0.0\n",
      "0.0375\n",
      "b'\\n\\x0b\\n\\x04loss\\x153\\xc1\\x0cA\\n\\x0f\\n\\x08accuracy\\x15\\x9a\\x99\\x19='\n",
      "8.79717\n",
      "1: полюбив полюбив полюбив полюбив полюбив полюбив полюбив подругой подругой подругой туманных туманных туманных туманных туманных туманных судьбой судьбой судьбой судьбой\n",
      "\n",
      "\n",
      "2: спят засвищет страданий страстных крови безнадежной высоко сонных вражда зарею дед красивой наугад живые смеется новь уединенный ярче <comma> второй\n",
      "\n",
      "\n",
      "3: полюбив полюбив полюбив полюбив полюбив полюбив подругой подругой подругой спирт туманных туманных туманных туманных туманных туманных судьбой судьбой судьбой судьбой\n",
      "\n",
      "\n",
      "4: волнами мальчики маленькая встать писал потух грядущих слабость музыканты скажите посреди видали веселый всегда сердит счастью пустыни кусты лукавой наслаждений\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test very simple model\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        model = Model(sess, seq_length=20, vocab_size=vocab_size, embed_dim=300, verbas = True,  state_sizes=[16,16])\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        gen = sequenses_generator(get_data(), 16, 20)\n",
    "        batch = gen.__next__()\n",
    "        model.train_on_batch(batch, learning_rate = 1e-3)\n",
    "        model.reset_state()\n",
    "        loggin(model.step(1))\n",
    "        loggin(model.get_accuracy_for_seq(\"а и а нет любовь <period>\"))\n",
    "        loggin(model.get_accuracy(batch))\n",
    "        loggin(model.get_summary(batch))\n",
    "        loggin(model.get_loss(batch))\n",
    "        loggin(\"1:\", decode(generate(model, max_size = 20, sampling = False, pattern = None)))\n",
    "        loggin(\"\\n\")\n",
    "        loggin(\"2:\", decode(generate(model, max_size = 20, sampling = True, pattern = None)))\n",
    "        loggin(\"\\n\")\n",
    "        loggin(\"3:\", decode(generate(model, max_size = 20, sampling = False, pattern = \"а и а нет\")))\n",
    "        loggin(\"\\n\")\n",
    "        loggin(\"4:\", decode(generate(model, max_size = 20, sampling = True, pattern = \"а и а нет\")))\n",
    "        loggin(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, eps_count = 10, batch_len = 256, batchs_in_ep = 256, learning_rate = 1e-3):\n",
    "    \n",
    "    print('gen, before training sampling:+',decode(generate(model, max_size = 20, sampling = True)),'+')\n",
    "    print('gen, before training no sampling:+',decode(generate(model, max_size = 20, sampling = False)),'+')\n",
    "    \n",
    "    data = get_data()\n",
    "    # 5% for test/val data\n",
    "    test_size = len(data)//100 * 2\n",
    "\n",
    "    train_data = data[test_size:]\n",
    "    test_data = data[:test_size]\n",
    "    \n",
    "    batch_for_test_loss = sequenses_generator(test_data, len([ 1 for d in test_data if len(d)>=seq_length]),\n",
    "                                              seq_length, randomized = False).__next__()\n",
    "\n",
    "    data_gen = sequenses_generator(train_data, batch_len, seq_length)\n",
    "    \n",
    "    min_loss = model.get_loss(batch_for_test_loss)\n",
    "    \n",
    "    for ep in range(eps_count):\n",
    "        for batches_processed in tqdm(range(batchs_in_ep)):\n",
    "            train_x = data_gen.__next__()\n",
    "            train_loss = model.train_on_batch(train_x, learning_rate = learning_rate)\n",
    "        \n",
    "        loss = model.get_loss(batch_for_test_loss)\n",
    "        acc = model.get_accuracy(batch_for_test_loss)\n",
    "        \n",
    "        if min_loss > loss:\n",
    "            min_loss = loss\n",
    "            model.save(loss = loss)\n",
    "            \n",
    "        loggin('ep %s acc %s, last loss %s, train_loss: %s' % ( ep,str(acc), str(loss), str(train_loss) ) )\n",
    "        loggin('gen, sampling:+',decode(generate(model, max_size = 20, sampling = True)),'+')\n",
    "        loggin('gen, no sampling:+',decode(generate(model, max_size = 20, sampling = False)),'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NN ....\n",
      "input tensor shape: (?, 40)\n",
      "\t Learning graph:\n",
      "emb_layer shape: (?, 40, 300)\n",
      "lstm_output shape: (?, 40, 1024)\n",
      "start_position for slice: 4\n",
      "slice count: 35\n",
      "output_layer shape: (?, 35, 6631)\n",
      "targets shape: (?, 35)\n",
      "self.loss shape: ()\n",
      "\t Acc:\n",
      "pred_classes shape: (?,)\n",
      "y_classes shape: (?,)\n",
      "\t Prediction graph:\n",
      "pred_emb_layer shape: (1, 1, 300)\n",
      "predict_rnn_output shape: (1, 1, 1024)\n",
      "predict_output shape: (6631,)\n",
      "loaded from loss-5.0461-statesize-1024-cellcount-3-.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_waights/loss-5.0461-statesize-1024-cellcount-3-.ckpt\n",
      "gen, before training sampling:+ спирт отчий прекрасные сибирь сокола робкие прекрасные прекрасные палач прекрасные старшая молодым небесам палач знакома плащ сокола музыки знакома стужи +\n",
      "gen, before training no sampling:+ прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:43<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model_waights/loss-5.06741-statesize-1024-cellcount-3-.ckpt\n",
      "ep 0 acc 0.25291, last loss 5.06741, train_loss: 4.54541\n",
      "gen, sampling:+ палач мертвой заре дожди пустыней коня палач единственной молча трудно прекрасные сокола прекрасные прекрасные класс руси палач полюбив делить бои +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen, no sampling:+ прекрасные прекрасные палач сокола прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:43<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1 acc 0.251852, last loss 5.08184, train_loss: 4.39345\n",
      "gen, sampling:+ палач сокола прекрасные палач приятель чужим дядя палач сокола прекрасные глыбы старшая нежно узнала палач знакома небесным прекрасные песен старшая +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen, no sampling:+ прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные прекрасные палач прекрасные прекрасные +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:43<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2 acc 0.251852, last loss 5.10235, train_loss: 4.41621\n",
      "gen, sampling:+ палач растворилась красавицы палач ну союз засвищет посвящается ища зыбкой сестра посвящается прекрасные службы никак жестокой палач язвы мертвой самых +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen, no sampling:+ палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:43<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3 acc 0.253968, last loss 5.13099, train_loss: 4.34652\n",
      "gen, sampling:+ старшая язвы гусар повеет прекрасные класс счастливым голове союз степь реже недуги палач вышли прекрасные какой палач дрожа прекрасные союз +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen, no sampling:+ палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:43<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4 acc 0.255026, last loss 5.16478, train_loss: 4.34507\n",
      "gen, sampling:+ сошлись палач о смех прекрасные прекрасные прекрасные прекрасные палач имя плод плечами палач жалею палач утеха ловил знакома крепка полным +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen, no sampling:+ палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные палач прекрасные +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:50<04:52,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "# NN structure\n",
    "seq_length = 40\n",
    "embed_dim=300\n",
    "state_sizes = [1024,1024,1024]\n",
    "\n",
    "#learning parameters\n",
    "eps_count = 10\n",
    "batch_len = 256\n",
    "batchs_in_ep = 300\n",
    "learning_rate = 1e-4\n",
    "#if False load best parameters for model\n",
    "new_model = False\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        model = Model(sess, seq_length = seq_length, vocab_size = vocab_size,\n",
    "                      embed_dim = embed_dim, verbas = True,  state_sizes = state_sizes, grad_clip = True)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if not new_model: model.load_best()\n",
    "        \n",
    "        train(model, eps_count = eps_count, batch_len = batch_len, batchs_in_ep = batchs_in_ep, learning_rate = learning_rate)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
